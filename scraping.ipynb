{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a38b1de3-ba3d-4270-81e9-af7f54b5897e",
   "metadata": {
    "id": "a38b1de3-ba3d-4270-81e9-af7f54b5897e"
   },
   "outputs": [],
   "source": [
    "# !pip install BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f21f967-ba23-447e-abf1-8e740da05e7f",
   "metadata": {
    "id": "3f21f967-ba23-447e-abf1-8e740da05e7f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd583c-16cf-41b0-9ad9-7ff4651e30a4",
   "metadata": {
    "id": "23bd583c-16cf-41b0-9ad9-7ff4651e30a4"
   },
   "source": [
    "# Class Explanation: `NewsScraper`\n",
    "\n",
    "## Overview\n",
    "The `NewsScraper` class is designed for scraping news articles from three different Urdu news websites: Geo, Jang, and Express. The class has methods that cater to each site's unique structure and requirements. Below, we will go through the class and its methods, detailing what each function does, the input it takes, and the output it returns.\n",
    "\n",
    "## Class Definition\n",
    "\n",
    "```python\n",
    "class NewsScraper:\n",
    "    def __init__(self, id_=0):\n",
    "        self.id = id_\n",
    "```\n",
    "\n",
    "\n",
    "## Method 1: `get_express_articles`\n",
    "\n",
    "### Description\n",
    "Scrapes news articles from the Express website across categories like saqafat (entertainment), business, sports, science-technology, and world. The method navigates through multiple pages for each category to gather a more extensive dataset.\n",
    "\n",
    "### Input\n",
    "- **`max_pages`**: The number of pages to scrape for each category (default is 7).\n",
    "\n",
    "### Process\n",
    "- Iterates over each category and page.\n",
    "- Requests each category page and finds article cards within `<ul class='tedit-shortnews listing-page'>`.\n",
    "- Extracts the article's headline, link, and content by navigating through `<div class='horiz-news3-caption'>` and `<span class='story-text'>`.\n",
    "\n",
    "### Output\n",
    "- **Returns**: A tuple of:\n",
    "  - A Pandas DataFrame containing columns: `id`, `title`, and `link`).\n",
    "  - A dictionary `express_contents` where the key is the article ID and the value is the article content.\n",
    "\n",
    "### Data Structure\n",
    "- Article cards are identified by `<li>` tags.\n",
    "- Content is structured within `<span class='story-text'>` and `<p>` tags.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8fc81de-6bc7-4bde-92e4-1512dcf43aa0",
   "metadata": {
    "id": "d8fc81de-6bc7-4bde-92e4-1512dcf43aa0"
   },
   "outputs": [],
   "source": [
    "class NewsScraper:\n",
    "    def __init__(self,id_=0):\n",
    "        self.id = id_\n",
    "\n",
    "  # write functions to scrape from other websites\n",
    "\n",
    "    def get_express_articles(self, max_pages=14):\n",
    "        express_df = {\n",
    "            \"id\": [],\n",
    "            \"title\": [],\n",
    "            \"link\": [],\n",
    "            \"content\": [],\n",
    "            \"gold_label\": [],\n",
    "            \"news_channel\": [], # optional\n",
    "        }\n",
    "        base_url = 'https://www.express.pk'\n",
    "        categories = ['saqafat', 'business', 'sports', 'science', 'world']   # saqafat is entertainment category\n",
    "\n",
    "        # Iterating over the specified number of pages\n",
    "        for category in categories:\n",
    "            for page in range(1, max_pages + 1):\n",
    "                print(f\"Scraping page {page} of category '{category}'...\")\n",
    "                url = f\"{base_url}/{category}/archives?page={page}\"\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Finding article cards\n",
    "                cards = soup.find('ul', class_='tedit-shortnews listing-page').find_all('li')  # Adjust class as per actual site structure\n",
    "                print(f\"\\t--> Found {len(cards)} articles on page {page} of '{category}'.\")\n",
    "\n",
    "                success_count = 0\n",
    "\n",
    "                for card in cards:\n",
    "                    try:\n",
    "                        div = card.find('div',class_='horiz-news3-caption')\n",
    "\n",
    "                        # Article Title\n",
    "                        headline = div.find('a').get_text(strip=True).replace('\\xa0', ' ')\n",
    "\n",
    "                        # Article link\n",
    "                        link = div.find('a')['href']\n",
    "\n",
    "                        # Requesting the content from each article's link\n",
    "                        article_response = requests.get(link)\n",
    "                        article_response.raise_for_status()\n",
    "                        content_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "                        # Content arranged in paras inside <span> tags\n",
    "                        paras = content_soup.find('span',class_='story-text').find_all('p')\n",
    "\n",
    "                        combined_text = \" \".join(\n",
    "                        p.get_text(strip=True).replace('\\xa0', ' ').replace('\\u200b', '')\n",
    "                        for p in paras if p.get_text(strip=True)\n",
    "                        )\n",
    "\n",
    "                        # Storing data\n",
    "                        express_df['id'].append(self.id)\n",
    "                        express_df['title'].append(headline)\n",
    "                        express_df['link'].append(link)\n",
    "                        express_df['gold_label'].append(category.replace('saqafat','entertainment').replace('science','science-technology'))\n",
    "                        express_df['content'].append(combined_text)\n",
    "                        express_df[\"news_channel\"].append(\"Express News\")  # Optional\n",
    "\n",
    "                        # Increment ID and success count\n",
    "                        self.id += 1\n",
    "                        success_count += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\t--> Failed to scrape an article on page {page} of '{category}': {e}\")\n",
    "\n",
    "                print(f\"\\t--> Successfully scraped {success_count} articles from page {page} of '{category}'.\")\n",
    "            print('')\n",
    "\n",
    "        return pd.DataFrame(express_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_dunya_articles(self, max_pages=14):\n",
    "        dunya_df = {\n",
    "            \"id\": [],\n",
    "            \"title\": [],\n",
    "            \"link\": [],\n",
    "            \"content\": [],\n",
    "            \"gold_label\": [],\n",
    "            \"news_channel\": [], # optional\n",
    "        }\n",
    "        base_url = 'https://urdu.dunyanews.tv'\n",
    "        categories = ['Entertainment', 'Pakistan', 'World', 'Sports', 'Business']\n",
    "\n",
    "        for category in categories:\n",
    "            for page in range(1, max_pages + 1):\n",
    "                print(f\"Scraping page {page} of category '{category}'...\")\n",
    "                url = f\"{base_url}/index.php/ur/{category}?page={page}\"\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                news_boxes = soup.find_all(\"div\", class_=\"cNewsBox\")\n",
    "                print(f\"\\t--> Found {len(news_boxes)} articles on page {page} of '{category}'.\")\n",
    "\n",
    "                success_count = 0\n",
    "\n",
    "                for news in news_boxes:\n",
    "                    try:\n",
    "                        title_tag = news.find(\"h3\")\n",
    "                        if title_tag:\n",
    "                            link_tag = title_tag.find(\"a\")\n",
    "                            if link_tag:\n",
    "                                title = link_tag.get_text(strip=True)\n",
    "                                link = base_url + link_tag['href']\n",
    "                            else:\n",
    "                                print(\"\\t--> Skipping article due to missing link.\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(\"\\t--> Skipping article due to missing title tag.\")\n",
    "                            continue\n",
    "\n",
    "                        article_response = requests.get(link)\n",
    "                        article_response.raise_for_status()\n",
    "                        content_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "\n",
    "                        content = \"\"\n",
    "                        content_div = content_soup.find(\"div\", class_=\"main-news\") \n",
    "                        if content_div:\n",
    "                            content_paras = content_div.find_all(\"p\")\n",
    "                            content = \" \".join(\n",
    "                                p.get_text(strip=True).replace('\\xa0', ' ').replace('\\u200b', '')\n",
    "                                for p in content_paras if p.get_text(strip=True)\n",
    "                            )\n",
    "\n",
    "                        if not content:\n",
    "                            print(f\"\\t--> Skipping article '{title}' due to missing content.\")\n",
    "                            continue\n",
    "\n",
    "                        dunya_df['id'].append(self.id)\n",
    "                        dunya_df['title'].append(title)\n",
    "                        dunya_df['link'].append(link)\n",
    "                        dunya_df['gold_label'].append(category)\n",
    "                        dunya_df['content'].append(content)\n",
    "                        dunya_df[\"news_channel\"].append(\"Dunya News\")  # Optional\n",
    "\n",
    "                        self.id += 1\n",
    "                        success_count += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\t--> Failed to scrape article due to: {e}\")\n",
    "\n",
    "                print(f\"\\t--> Successfully scraped {success_count} articles from page {page} of '{category}'.\")\n",
    "            print('')\n",
    "\n",
    "        return pd.DataFrame(dunya_df)\n",
    "\n",
    "\n",
    "\n",
    "    def get_geo_articles(self, max_pages=14):\n",
    "        geo_df = {\n",
    "            \"id\": [],\n",
    "            \"title\": [],\n",
    "            \"link\": [],\n",
    "            \"content\": [],\n",
    "            \"gold_label\": [],\n",
    "            \"news_channel\": [], # optional\n",
    "        }\n",
    "        base_url = 'https://urdu.geo.tv/category'\n",
    "        # categories = ['business']\n",
    "        categories = ['business', 'entertainment', 'sports', 'world']\n",
    "\n",
    "        for category in categories:\n",
    "            for page in range(1, max_pages + 1):\n",
    "                print(f\"Scraping page {page} of category '{category}'...\")\n",
    "                url = f\"{base_url}/{category}/page/{page}/\"\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 403:\n",
    "                    print(\"Request was blocked by the server.\")\n",
    "                    break\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                articles = soup.find_all(\"div\", class_=\"m_pic\")\n",
    "\n",
    "                print(f\"\\t--> Found {len(articles)} articles on page {page} of '{category}'.\")\n",
    "\n",
    "                success_count = 0\n",
    "                for article in articles:\n",
    "                    try:\n",
    "                        title_tag = article.find(\"a\", class_=\"open-section\")\n",
    "                        if title_tag:\n",
    "                            title = title_tag.get(\"title\", \"\").strip()\n",
    "                            link = title_tag[\"href\"]\n",
    "                        else:\n",
    "                            print(\"\\t--> Skipping article due to missing title or link.\")\n",
    "                            continue\n",
    "\n",
    "                        article_response = requests.get(link)\n",
    "                        article_response.raise_for_status()\n",
    "                        content_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "                        \n",
    "                        content_div = content_soup.find(\"div\", class_=\"content-area\")\n",
    "                        content = \"\"\n",
    "                        if content_div:\n",
    "                            content = \" \".join(\n",
    "                                p.get_text(strip=True)\n",
    "                                for p in content_div.find_all(\"p\")\n",
    "                            )\n",
    "\n",
    "                        if not content:\n",
    "                            print(f\"\\t--> Skipping article '{title}' due to missing content.\")\n",
    "                            continue\n",
    "\n",
    "                        geo_df[\"id\"].append(self.id)\n",
    "                        geo_df[\"title\"].append(title)\n",
    "                        geo_df[\"link\"].append(link)\n",
    "                        geo_df[\"gold_label\"].append(category.capitalize())\n",
    "                        geo_df[\"content\"].append(content)\n",
    "                        geo_df[\"news_channel\"].append(\"Geo News\")  # Optional\n",
    "\n",
    "                        self.id += 1\n",
    "                        success_count += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\t--> Failed to scrape article due to: {e}\")\n",
    "\n",
    "                print(f\"\\t--> Successfully scraped {success_count} articles from page {page} of '{category}'.\")\n",
    "            print('')\n",
    "\n",
    "        return pd.DataFrame(geo_df)\n",
    "\n",
    "\n",
    "\n",
    "    def get_jang_articles(self):\n",
    "        jang_df = {\n",
    "            \"id\": [],\n",
    "            \"title\": [],\n",
    "            \"link\": [],\n",
    "            \"content\": [],\n",
    "            \"gold_label\": [],\n",
    "            \"news_channel\": [], # optional\n",
    "        }\n",
    "\n",
    "        base_url = 'https://jang.com.pk/category/latest-news'\n",
    "        categories = ['entertainment', 'sports', 'world', 'health-science']\n",
    "        # categories = ['health-science']\n",
    "\n",
    "        for category in categories:\n",
    "            print(f\"Scraping category '{category}'...\")\n",
    "            url = f\"{base_url}/{category}/\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            articles = soup.find('ul',class_='scrollPaginationNew__').find_all(\"li\")\n",
    "            print(f\"\\t--> Found {len(articles)} articles in '{category}'.\")\n",
    "\n",
    "            success_count = 0\n",
    "            for article in articles:\n",
    "                try:\n",
    "                    if article.get(\"class\") == [\"ad_latest_stories\"]:\n",
    "                        continue\n",
    "                    \n",
    "                    title, link = None, None\n",
    "\n",
    "                    main_pic = article.find(\"div\", class_=\"main-pic\")\n",
    "                    if main_pic:\n",
    "                        link_tag = main_pic.find(\"a\", href=True)\n",
    "                        if link_tag:\n",
    "                            link = link_tag[\"href\"]\n",
    "                            title = link_tag.get(\"title\", \"\").strip()\n",
    "                            print(title)\n",
    "\n",
    "                    if not title or not link:\n",
    "                        main_heading = article.find(\"div\", class_=\"main-heading\")\n",
    "                        if main_heading:\n",
    "                            link_tag = main_heading.find(\"a\", href=True)\n",
    "                            if link_tag:\n",
    "                                link = link_tag[\"href\"]\n",
    "                                title_tag = link_tag.find(\"h2\")\n",
    "                                title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
    "\n",
    "                    if not title or not link:\n",
    "                        print(\"\\t--> Skipping article due to missing title or link.\")\n",
    "                        continue\n",
    "\n",
    "                    article_response = requests.get(link)\n",
    "                    article_response.raise_for_status()\n",
    "                    content_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "\n",
    "                    content_div = content_soup.find(\"div\", class_=\"detail_view_content\")\n",
    "                    content = \"\"\n",
    "                    if content_div:\n",
    "                        content = \" \".join(\n",
    "                            p.get_text(strip=True)\n",
    "                            for p in content_div.find_all(\"p\")\n",
    "                        )\n",
    "\n",
    "                    if not content:\n",
    "                        print(f\"\\t--> Skipping article '{title}' due to missing content.\")\n",
    "                        continue\n",
    "\n",
    "                    jang_df[\"id\"].append(self.id)\n",
    "                    jang_df[\"title\"].append(title)\n",
    "                    jang_df[\"link\"].append(link)\n",
    "                    jang_df[\"gold_label\"].append(category.capitalize())\n",
    "                    jang_df[\"content\"].append(content)\n",
    "                    jang_df[\"news_channel\"].append(\"Jang\")  # Optional\n",
    "\n",
    "                    self.id += 1\n",
    "                    success_count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\t--> Failed to scrape article due to: {e}\")\n",
    "\n",
    "            print(f\"\\t--> Successfully scraped {success_count} articles from '{category}'.\")\n",
    "\n",
    "        return pd.DataFrame(jang_df)\n",
    "\n",
    "\n",
    "\n",
    "    def get_dawn_articles(self):\n",
    "        dawn_df = {\n",
    "            \"id\": [],\n",
    "            \"title\": [],\n",
    "            \"link\": [],\n",
    "            \"content\": [],\n",
    "            \"gold_label\": [],\n",
    "            \"news_channel\": [], # optional\n",
    "        }\n",
    "        base_url = 'https://www.dawnnews.tv/'\n",
    "        categories = ['business','sport', 'tech', 'world']\n",
    "\n",
    "        for category in categories:\n",
    "            print(f\"Scraping category '{category}'...\")\n",
    "            url = f\"{base_url}/{category}/\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            articles = soup.find('div',class_='flex flex-row w-auto').find_all(\"article\")\n",
    "            print(f\"\\t--> Found {len(articles)} articles in '{category}'.\")\n",
    "\n",
    "            success_count = 0\n",
    "            for article in articles:\n",
    "                try:\n",
    "                    title, link = None, None\n",
    "\n",
    "                    main_div = article.find(\"h2\", class_=\"story__title\")\n",
    "                    if main_div:\n",
    "                        link_tag = main_div.find(\"a\", href=True)\n",
    "                        if link_tag:\n",
    "                            link = link_tag[\"href\"]\n",
    "                            title = link_tag.text.strip()\n",
    "                            print(title)\n",
    "\n",
    "                    if not title or not link:\n",
    "                        print(\"\\t--> Skipping article due to missing title or link.\")\n",
    "                        continue\n",
    "\n",
    "                    article_response = requests.get(link)\n",
    "                    article_response.raise_for_status()\n",
    "                    content_soup = BeautifulSoup(article_response.text, \"html.parser\")\n",
    "\n",
    "                    content_div = content_soup.find(\"div\", class_=\"story__content\")\n",
    "                    content = \"\"\n",
    "                    if content_div:\n",
    "                        content = \" \".join(\n",
    "                            p.get_text(strip=True)\n",
    "                            for p in content_div.find_all(\"p\")\n",
    "                        )\n",
    "\n",
    "                    if not content:\n",
    "                        print(f\"\\t--> Skipping article '{title}' due to missing content.\")\n",
    "                        continue\n",
    "\n",
    "                    dawn_df[\"id\"].append(self.id)\n",
    "                    dawn_df[\"title\"].append(title)\n",
    "                    dawn_df[\"link\"].append(link)\n",
    "                    dawn_df[\"gold_label\"].append(category.capitalize())\n",
    "                    dawn_df[\"content\"].append(content)\n",
    "                    dawn_df[\"news_channel\"].append(\"Dawn News\")  # Optional\n",
    "\n",
    "                    self.id += 1\n",
    "                    success_count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\t--> Failed to scrape article due to: {e}\")\n",
    "\n",
    "            print(f\"\\t--> Successfully scraped {success_count} articles from '{category}'.\")\n",
    "\n",
    "        return pd.DataFrame(dawn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a8ad94-10b0-4458-bb7f-3402eecd80d1",
   "metadata": {
    "id": "e9a8ad94-10b0-4458-bb7f-3402eecd80d1"
   },
   "outputs": [],
   "source": [
    "scraper = NewsScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "321373e7-8ef4-468f-81d0-8be61fe2ba85",
   "metadata": {
    "id": "321373e7-8ef4-468f-81d0-8be61fe2ba85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 1 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 1 of 'saqafat'.\n",
      "Scraping page 2 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 2 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 2 of 'saqafat'.\n",
      "Scraping page 3 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 3 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 3 of 'saqafat'.\n",
      "Scraping page 4 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 4 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 4 of 'saqafat'.\n",
      "Scraping page 5 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 5 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 5 of 'saqafat'.\n",
      "Scraping page 6 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 6 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 6 of 'saqafat'.\n",
      "Scraping page 7 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 7 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 7 of 'saqafat'.\n",
      "Scraping page 8 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 8 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 8 of 'saqafat'.\n",
      "Scraping page 9 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 9 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 9 of 'saqafat'.\n",
      "Scraping page 10 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 10 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 10 of 'saqafat'.\n",
      "Scraping page 11 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 11 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 11 of 'saqafat'.\n",
      "Scraping page 12 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 12 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 12 of 'saqafat'.\n",
      "Scraping page 13 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 13 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 13 of 'saqafat'.\n",
      "Scraping page 14 of category 'saqafat'...\n",
      "\t--> Found 10 articles on page 14 of 'saqafat'.\n",
      "\t--> Successfully scraped 10 articles from page 14 of 'saqafat'.\n",
      "\n",
      "Scraping page 1 of category 'business'...\n",
      "\t--> Found 10 articles on page 1 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 1 of 'business'.\n",
      "Scraping page 2 of category 'business'...\n",
      "\t--> Found 10 articles on page 2 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 2 of 'business'.\n",
      "Scraping page 3 of category 'business'...\n",
      "\t--> Found 10 articles on page 3 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 3 of 'business'.\n",
      "Scraping page 4 of category 'business'...\n",
      "\t--> Found 10 articles on page 4 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 4 of 'business'.\n",
      "Scraping page 5 of category 'business'...\n",
      "\t--> Found 10 articles on page 5 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 5 of 'business'.\n",
      "Scraping page 6 of category 'business'...\n",
      "\t--> Found 10 articles on page 6 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 6 of 'business'.\n",
      "Scraping page 7 of category 'business'...\n",
      "\t--> Found 10 articles on page 7 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 7 of 'business'.\n",
      "Scraping page 8 of category 'business'...\n",
      "\t--> Found 10 articles on page 8 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 8 of 'business'.\n",
      "Scraping page 9 of category 'business'...\n",
      "\t--> Found 10 articles on page 9 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 9 of 'business'.\n",
      "Scraping page 10 of category 'business'...\n",
      "\t--> Found 10 articles on page 10 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 10 of 'business'.\n",
      "Scraping page 11 of category 'business'...\n",
      "\t--> Found 10 articles on page 11 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 11 of 'business'.\n",
      "Scraping page 12 of category 'business'...\n",
      "\t--> Found 10 articles on page 12 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 12 of 'business'.\n",
      "Scraping page 13 of category 'business'...\n",
      "\t--> Found 10 articles on page 13 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 13 of 'business'.\n",
      "Scraping page 14 of category 'business'...\n",
      "\t--> Found 10 articles on page 14 of 'business'.\n",
      "\t--> Successfully scraped 10 articles from page 14 of 'business'.\n",
      "\n",
      "Scraping page 1 of category 'sports'...\n",
      "\t--> Found 10 articles on page 1 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 1 of 'sports'.\n",
      "Scraping page 2 of category 'sports'...\n",
      "\t--> Found 10 articles on page 2 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 2 of 'sports'.\n",
      "Scraping page 3 of category 'sports'...\n",
      "\t--> Found 10 articles on page 3 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 3 of 'sports'.\n",
      "Scraping page 4 of category 'sports'...\n",
      "\t--> Found 10 articles on page 4 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 4 of 'sports'.\n",
      "Scraping page 5 of category 'sports'...\n",
      "\t--> Found 10 articles on page 5 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 5 of 'sports'.\n",
      "Scraping page 6 of category 'sports'...\n",
      "\t--> Found 10 articles on page 6 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 6 of 'sports'.\n",
      "Scraping page 7 of category 'sports'...\n",
      "\t--> Found 10 articles on page 7 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 7 of 'sports'.\n",
      "Scraping page 8 of category 'sports'...\n",
      "\t--> Found 10 articles on page 8 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 8 of 'sports'.\n",
      "Scraping page 9 of category 'sports'...\n",
      "\t--> Found 10 articles on page 9 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 9 of 'sports'.\n",
      "Scraping page 10 of category 'sports'...\n",
      "\t--> Found 10 articles on page 10 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 10 of 'sports'.\n",
      "Scraping page 11 of category 'sports'...\n",
      "\t--> Found 10 articles on page 11 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 11 of 'sports'.\n",
      "Scraping page 12 of category 'sports'...\n",
      "\t--> Found 10 articles on page 12 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 12 of 'sports'.\n",
      "Scraping page 13 of category 'sports'...\n",
      "\t--> Found 10 articles on page 13 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 13 of 'sports'.\n",
      "Scraping page 14 of category 'sports'...\n",
      "\t--> Found 10 articles on page 14 of 'sports'.\n",
      "\t--> Successfully scraped 10 articles from page 14 of 'sports'.\n",
      "\n",
      "Scraping page 1 of category 'science'...\n",
      "\t--> Found 10 articles on page 1 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 1 of 'science'.\n",
      "Scraping page 2 of category 'science'...\n",
      "\t--> Found 10 articles on page 2 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 2 of 'science'.\n",
      "Scraping page 3 of category 'science'...\n",
      "\t--> Found 10 articles on page 3 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 3 of 'science'.\n",
      "Scraping page 4 of category 'science'...\n",
      "\t--> Found 10 articles on page 4 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 4 of 'science'.\n",
      "Scraping page 5 of category 'science'...\n",
      "\t--> Found 10 articles on page 5 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 5 of 'science'.\n",
      "Scraping page 6 of category 'science'...\n",
      "\t--> Found 10 articles on page 6 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 6 of 'science'.\n",
      "Scraping page 7 of category 'science'...\n",
      "\t--> Found 10 articles on page 7 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 7 of 'science'.\n",
      "Scraping page 8 of category 'science'...\n",
      "\t--> Found 10 articles on page 8 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 8 of 'science'.\n",
      "Scraping page 9 of category 'science'...\n",
      "\t--> Found 10 articles on page 9 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 9 of 'science'.\n",
      "Scraping page 10 of category 'science'...\n",
      "\t--> Found 10 articles on page 10 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 10 of 'science'.\n",
      "Scraping page 11 of category 'science'...\n",
      "\t--> Found 10 articles on page 11 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 11 of 'science'.\n",
      "Scraping page 12 of category 'science'...\n",
      "\t--> Found 10 articles on page 12 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 12 of 'science'.\n",
      "Scraping page 13 of category 'science'...\n",
      "\t--> Found 10 articles on page 13 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 13 of 'science'.\n",
      "Scraping page 14 of category 'science'...\n",
      "\t--> Found 10 articles on page 14 of 'science'.\n",
      "\t--> Successfully scraped 10 articles from page 14 of 'science'.\n",
      "\n",
      "Scraping page 1 of category 'world'...\n",
      "\t--> Found 10 articles on page 1 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 1 of 'world'.\n",
      "Scraping page 2 of category 'world'...\n",
      "\t--> Found 10 articles on page 2 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 2 of 'world'.\n",
      "Scraping page 3 of category 'world'...\n",
      "\t--> Found 10 articles on page 3 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 3 of 'world'.\n",
      "Scraping page 4 of category 'world'...\n",
      "\t--> Found 10 articles on page 4 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 4 of 'world'.\n",
      "Scraping page 5 of category 'world'...\n",
      "\t--> Found 10 articles on page 5 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 5 of 'world'.\n",
      "Scraping page 6 of category 'world'...\n",
      "\t--> Found 10 articles on page 6 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 6 of 'world'.\n",
      "Scraping page 7 of category 'world'...\n",
      "\t--> Found 10 articles on page 7 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 7 of 'world'.\n",
      "Scraping page 8 of category 'world'...\n",
      "\t--> Found 10 articles on page 8 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 8 of 'world'.\n",
      "Scraping page 9 of category 'world'...\n",
      "\t--> Found 10 articles on page 9 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 9 of 'world'.\n",
      "Scraping page 10 of category 'world'...\n",
      "\t--> Found 10 articles on page 10 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 10 of 'world'.\n",
      "Scraping page 11 of category 'world'...\n",
      "\t--> Found 10 articles on page 11 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 11 of 'world'.\n",
      "Scraping page 12 of category 'world'...\n",
      "\t--> Found 10 articles on page 12 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 12 of 'world'.\n",
      "Scraping page 13 of category 'world'...\n",
      "\t--> Found 10 articles on page 13 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 13 of 'world'.\n",
      "Scraping page 14 of category 'world'...\n",
      "\t--> Found 10 articles on page 14 of 'world'.\n",
      "\t--> Successfully scraped 10 articles from page 14 of 'world'.\n",
      "\n",
      "Scraping page 1 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 1 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 1 of 'Entertainment'.\n",
      "Scraping page 2 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 2 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 2 of 'Entertainment'.\n",
      "Scraping page 3 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 3 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 3 of 'Entertainment'.\n",
      "Scraping page 4 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 4 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 4 of 'Entertainment'.\n",
      "Scraping page 5 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 5 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 5 of 'Entertainment'.\n",
      "Scraping page 6 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 6 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 6 of 'Entertainment'.\n",
      "Scraping page 7 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 7 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 7 of 'Entertainment'.\n",
      "Scraping page 8 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 8 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 8 of 'Entertainment'.\n",
      "Scraping page 9 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 9 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 9 of 'Entertainment'.\n",
      "Scraping page 10 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 10 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 10 of 'Entertainment'.\n",
      "Scraping page 11 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 11 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 11 of 'Entertainment'.\n",
      "Scraping page 12 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 12 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 12 of 'Entertainment'.\n",
      "Scraping page 13 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 13 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 13 of 'Entertainment'.\n",
      "Scraping page 14 of category 'Entertainment'...\n",
      "\t--> Found 18 articles on page 14 of 'Entertainment'.\n",
      "\t--> Successfully scraped 18 articles from page 14 of 'Entertainment'.\n",
      "\n",
      "Scraping page 1 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 1 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 1 of 'Pakistan'.\n",
      "Scraping page 2 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 2 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 2 of 'Pakistan'.\n",
      "Scraping page 3 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 3 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 3 of 'Pakistan'.\n",
      "Scraping page 4 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 4 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 4 of 'Pakistan'.\n",
      "Scraping page 5 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 5 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 5 of 'Pakistan'.\n",
      "Scraping page 6 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 6 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 6 of 'Pakistan'.\n",
      "Scraping page 7 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 7 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 7 of 'Pakistan'.\n",
      "Scraping page 8 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 8 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 8 of 'Pakistan'.\n",
      "Scraping page 9 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 9 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 9 of 'Pakistan'.\n",
      "Scraping page 10 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 10 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 10 of 'Pakistan'.\n",
      "Scraping page 11 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 11 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 11 of 'Pakistan'.\n",
      "Scraping page 12 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 12 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 12 of 'Pakistan'.\n",
      "Scraping page 13 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 13 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 13 of 'Pakistan'.\n",
      "Scraping page 14 of category 'Pakistan'...\n",
      "\t--> Found 18 articles on page 14 of 'Pakistan'.\n",
      "\t--> Successfully scraped 18 articles from page 14 of 'Pakistan'.\n",
      "\n",
      "Scraping page 1 of category 'World'...\n",
      "\t--> Found 18 articles on page 1 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 1 of 'World'.\n",
      "Scraping page 2 of category 'World'...\n",
      "\t--> Found 18 articles on page 2 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 2 of 'World'.\n",
      "Scraping page 3 of category 'World'...\n",
      "\t--> Found 18 articles on page 3 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 3 of 'World'.\n",
      "Scraping page 4 of category 'World'...\n",
      "\t--> Found 18 articles on page 4 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 4 of 'World'.\n",
      "Scraping page 5 of category 'World'...\n",
      "\t--> Found 18 articles on page 5 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 5 of 'World'.\n",
      "Scraping page 6 of category 'World'...\n",
      "\t--> Found 18 articles on page 6 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 6 of 'World'.\n",
      "Scraping page 7 of category 'World'...\n",
      "\t--> Found 18 articles on page 7 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 7 of 'World'.\n",
      "Scraping page 8 of category 'World'...\n",
      "\t--> Found 18 articles on page 8 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 8 of 'World'.\n",
      "Scraping page 9 of category 'World'...\n",
      "\t--> Found 18 articles on page 9 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 9 of 'World'.\n",
      "Scraping page 10 of category 'World'...\n",
      "\t--> Found 18 articles on page 10 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 10 of 'World'.\n",
      "Scraping page 11 of category 'World'...\n",
      "\t--> Found 18 articles on page 11 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 11 of 'World'.\n",
      "Scraping page 12 of category 'World'...\n",
      "\t--> Found 18 articles on page 12 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 12 of 'World'.\n",
      "Scraping page 13 of category 'World'...\n",
      "\t--> Found 18 articles on page 13 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 13 of 'World'.\n",
      "Scraping page 14 of category 'World'...\n",
      "\t--> Found 18 articles on page 14 of 'World'.\n",
      "\t--> Successfully scraped 18 articles from page 14 of 'World'.\n",
      "\n",
      "Scraping page 1 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 1 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 1 of 'Sports'.\n",
      "Scraping page 2 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 2 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 2 of 'Sports'.\n",
      "Scraping page 3 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 3 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 3 of 'Sports'.\n",
      "Scraping page 4 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 4 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 4 of 'Sports'.\n",
      "Scraping page 5 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 5 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 5 of 'Sports'.\n",
      "Scraping page 6 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 6 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 6 of 'Sports'.\n",
      "Scraping page 7 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 7 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 7 of 'Sports'.\n",
      "Scraping page 8 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 8 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 8 of 'Sports'.\n",
      "Scraping page 9 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 9 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 9 of 'Sports'.\n",
      "Scraping page 10 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 10 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 10 of 'Sports'.\n",
      "Scraping page 11 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 11 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 11 of 'Sports'.\n",
      "Scraping page 12 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 12 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 12 of 'Sports'.\n",
      "Scraping page 13 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 13 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 13 of 'Sports'.\n",
      "Scraping page 14 of category 'Sports'...\n",
      "\t--> Found 18 articles on page 14 of 'Sports'.\n",
      "\t--> Successfully scraped 18 articles from page 14 of 'Sports'.\n",
      "\n",
      "Scraping page 1 of category 'Business'...\n",
      "\t--> Found 18 articles on page 1 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 1 of 'Business'.\n",
      "Scraping page 2 of category 'Business'...\n",
      "\t--> Found 18 articles on page 2 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 2 of 'Business'.\n",
      "Scraping page 3 of category 'Business'...\n",
      "\t--> Found 18 articles on page 3 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 3 of 'Business'.\n",
      "Scraping page 4 of category 'Business'...\n",
      "\t--> Found 18 articles on page 4 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 4 of 'Business'.\n",
      "Scraping page 5 of category 'Business'...\n",
      "\t--> Found 18 articles on page 5 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 5 of 'Business'.\n",
      "Scraping page 6 of category 'Business'...\n",
      "\t--> Found 18 articles on page 6 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 6 of 'Business'.\n",
      "Scraping page 7 of category 'Business'...\n",
      "\t--> Found 18 articles on page 7 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 7 of 'Business'.\n",
      "Scraping page 8 of category 'Business'...\n",
      "\t--> Found 18 articles on page 8 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 8 of 'Business'.\n",
      "Scraping page 9 of category 'Business'...\n",
      "\t--> Found 18 articles on page 9 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 9 of 'Business'.\n",
      "Scraping page 10 of category 'Business'...\n",
      "\t--> Found 18 articles on page 10 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 10 of 'Business'.\n",
      "Scraping page 11 of category 'Business'...\n",
      "\t--> Found 18 articles on page 11 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 11 of 'Business'.\n",
      "Scraping page 12 of category 'Business'...\n",
      "\t--> Found 18 articles on page 12 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 12 of 'Business'.\n",
      "Scraping page 13 of category 'Business'...\n",
      "\t--> Found 18 articles on page 13 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 13 of 'Business'.\n",
      "Scraping page 14 of category 'Business'...\n",
      "\t--> Found 18 articles on page 14 of 'Business'.\n",
      "\t--> Successfully scraped 18 articles from page 14 of 'Business'.\n",
      "\n",
      "Scraping page 1 of category 'business'...\n",
      "\t--> Found 19 articles on page 1 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 1 of 'business'.\n",
      "Scraping page 2 of category 'business'...\n",
      "\t--> Found 19 articles on page 2 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 2 of 'business'.\n",
      "Scraping page 3 of category 'business'...\n",
      "\t--> Found 19 articles on page 3 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 3 of 'business'.\n",
      "Scraping page 4 of category 'business'...\n",
      "\t--> Found 19 articles on page 4 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 4 of 'business'.\n",
      "Scraping page 5 of category 'business'...\n",
      "\t--> Found 19 articles on page 5 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 5 of 'business'.\n",
      "Scraping page 6 of category 'business'...\n",
      "\t--> Found 19 articles on page 6 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 6 of 'business'.\n",
      "Scraping page 7 of category 'business'...\n",
      "\t--> Found 19 articles on page 7 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 7 of 'business'.\n",
      "Scraping page 8 of category 'business'...\n",
      "\t--> Found 19 articles on page 8 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 8 of 'business'.\n",
      "Scraping page 9 of category 'business'...\n",
      "\t--> Found 19 articles on page 9 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 9 of 'business'.\n",
      "Scraping page 10 of category 'business'...\n",
      "\t--> Found 19 articles on page 10 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 10 of 'business'.\n",
      "Scraping page 11 of category 'business'...\n",
      "\t--> Found 19 articles on page 11 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 11 of 'business'.\n",
      "Scraping page 12 of category 'business'...\n",
      "\t--> Found 19 articles on page 12 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 12 of 'business'.\n",
      "Scraping page 13 of category 'business'...\n",
      "\t--> Found 19 articles on page 13 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 13 of 'business'.\n",
      "Scraping page 14 of category 'business'...\n",
      "\t--> Found 19 articles on page 14 of 'business'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 14 of 'business'.\n",
      "\n",
      "Scraping page 1 of category 'entertainment'...\n",
      "\t--> Found 19 articles on page 1 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 1 of 'entertainment'.\n",
      "Scraping page 2 of category 'entertainment'...\n",
      "\t--> Found 19 articles on page 2 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 2 of 'entertainment'.\n",
      "Scraping page 3 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 3 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 3 of 'entertainment'.\n",
      "Scraping page 4 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 4 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 4 of 'entertainment'.\n",
      "Scraping page 5 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 5 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 5 of 'entertainment'.\n",
      "Scraping page 6 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 6 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 6 of 'entertainment'.\n",
      "Scraping page 7 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 7 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 7 of 'entertainment'.\n",
      "Scraping page 8 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 8 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 8 of 'entertainment'.\n",
      "Scraping page 9 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 9 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 9 of 'entertainment'.\n",
      "Scraping page 10 of category 'entertainment'...\n",
      "\t--> Found 18 articles on page 10 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 10 of 'entertainment'.\n",
      "Scraping page 11 of category 'entertainment'...\n",
      "\t--> Found 19 articles on page 11 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 11 of 'entertainment'.\n",
      "Scraping page 12 of category 'entertainment'...\n",
      "\t--> Found 19 articles on page 12 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 12 of 'entertainment'.\n",
      "Scraping page 13 of category 'entertainment'...\n",
      "\t--> Found 19 articles on page 13 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 13 of 'entertainment'.\n",
      "Scraping page 14 of category 'entertainment'...\n",
      "\t--> Found 19 articles on page 14 of 'entertainment'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 14 of 'entertainment'.\n",
      "\n",
      "Scraping page 1 of category 'sports'...\n",
      "\t--> Found 19 articles on page 1 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 1 of 'sports'.\n",
      "Scraping page 2 of category 'sports'...\n",
      "\t--> Found 19 articles on page 2 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 2 of 'sports'.\n",
      "Scraping page 3 of category 'sports'...\n",
      "\t--> Found 19 articles on page 3 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 3 of 'sports'.\n",
      "Scraping page 4 of category 'sports'...\n",
      "\t--> Found 19 articles on page 4 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 4 of 'sports'.\n",
      "Scraping page 5 of category 'sports'...\n",
      "\t--> Found 19 articles on page 5 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 5 of 'sports'.\n",
      "Scraping page 6 of category 'sports'...\n",
      "\t--> Found 19 articles on page 6 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 6 of 'sports'.\n",
      "Scraping page 7 of category 'sports'...\n",
      "\t--> Found 19 articles on page 7 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 7 of 'sports'.\n",
      "Scraping page 8 of category 'sports'...\n",
      "\t--> Found 19 articles on page 8 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 8 of 'sports'.\n",
      "Scraping page 9 of category 'sports'...\n",
      "\t--> Found 19 articles on page 9 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 9 of 'sports'.\n",
      "Scraping page 10 of category 'sports'...\n",
      "\t--> Found 19 articles on page 10 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 10 of 'sports'.\n",
      "Scraping page 11 of category 'sports'...\n",
      "\t--> Found 19 articles on page 11 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 11 of 'sports'.\n",
      "Scraping page 12 of category 'sports'...\n",
      "\t--> Found 19 articles on page 12 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 12 of 'sports'.\n",
      "Scraping page 13 of category 'sports'...\n",
      "\t--> Found 19 articles on page 13 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 13 of 'sports'.\n",
      "Scraping page 14 of category 'sports'...\n",
      "\t--> Found 19 articles on page 14 of 'sports'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 14 of 'sports'.\n",
      "\n",
      "Scraping page 1 of category 'world'...\n",
      "\t--> Found 19 articles on page 1 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 1 of 'world'.\n",
      "Scraping page 2 of category 'world'...\n",
      "\t--> Found 19 articles on page 2 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 2 of 'world'.\n",
      "Scraping page 3 of category 'world'...\n",
      "\t--> Found 19 articles on page 3 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 3 of 'world'.\n",
      "Scraping page 4 of category 'world'...\n",
      "\t--> Found 19 articles on page 4 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 9 articles from page 4 of 'world'.\n",
      "Scraping page 5 of category 'world'...\n",
      "\t--> Found 18 articles on page 5 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 5 of 'world'.\n",
      "Scraping page 6 of category 'world'...\n",
      "\t--> Found 18 articles on page 6 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 6 of 'world'.\n",
      "Scraping page 7 of category 'world'...\n",
      "\t--> Found 18 articles on page 7 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 7 of 'world'.\n",
      "Scraping page 8 of category 'world'...\n",
      "\t--> Found 18 articles on page 8 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 8 of 'world'.\n",
      "Scraping page 9 of category 'world'...\n",
      "\t--> Found 18 articles on page 9 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 9 of 'world'.\n",
      "Scraping page 10 of category 'world'...\n",
      "\t--> Found 18 articles on page 10 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 10 of 'world'.\n",
      "Scraping page 11 of category 'world'...\n",
      "\t--> Found 18 articles on page 11 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 11 of 'world'.\n",
      "Scraping page 12 of category 'world'...\n",
      "\t--> Found 18 articles on page 12 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 12 of 'world'.\n",
      "Scraping page 13 of category 'world'...\n",
      "\t--> Found 18 articles on page 13 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 13 of 'world'.\n",
      "Scraping page 14 of category 'world'...\n",
      "\t--> Found 18 articles on page 14 of 'world'.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Successfully scraped 8 articles from page 14 of 'world'.\n",
      "\n",
      "Scraping category 'entertainment'...\n",
      "\t--> Found 102 articles in 'entertainment'.\n",
      "کیا نیلم منیر شادی کے بندھ میں بندھنے والی ہیں؟\n",
      "ڈاکٹر ہما میر کی آواز میں ’ہوجمالو ‘ نے محفل لوٹ لی\n",
      "بشنوئی گینگ نے گلوکار بادشاہ کے کلب کو نشانہ بنانے کی وجہ بتا دی\n",
      "زینب رضا کا سابق صدر پرویز مشرف سے کیا تعلق ہے؟\n",
      "دعا لیپا کی بوائے فرینڈ کالم ٹرنر کیساتھ بھارت میں ڈیٹنگ\n",
      "سویرا ندیم کی والدہ انتقال کر گئیں\n",
      "طلاق کے بعد مفاہمت خارج از امکان نہیں، سائرہ بانو کی وکیل کا بیان\n",
      "شادی سے قبل ایشوریا کے ساتھ ڈیٹنگ کی تردید، دھنوش کا پرانا بیان وائرل\n",
      "کرینہ کپور کے کزن کی روکا تقریب کی نئی تصاویر سامنے آ گئیں\n",
      "جنید جمشید نے کتنی شادیاں کی تھیں؟ بیٹے نے بتا دیا\n",
      "علی ظفر کی آئس باتھ لیتے ویڈیو سوشل میڈیا پر وائرل، مداحوں کے دلچسپ تبصرے\n",
      "دھنوش اور ایشوریا کی باضابطہ طلاق ہوگئی\n",
      "شوہر کے افیئرز سے آگاہ ہوں، گرل فرینڈز ادیتیا سے جو چاہتی تھیں نہ ملنے پر الزامات لگائے، زرینہ وہاب\n",
      "کیرتی سریش نے انٹونی تھاٹل کے ساتھ تعلقات کی تصدیق کردی\n",
      "کیریئر میں ناکامی کے باوجود ویویک اوبرائے کا 1200 کروڑ کا بزنس ایمپائر\n",
      "تامل اداکار کی پروفیشنل ریسنگ سرکٹ پر واپسی، سوشل میڈیا پر تصویر وائرل\n",
      "انوشکا اور ویرات کے بیٹے کی سوشل میڈیا پر وائرل تصویر کی حقیقت سامنے آگئی\n",
      "3 شادیاں کرنیوالی ریحام خان نے ہانیہ عامر کو شادی کیلئے منع کیوں کیا؟\n",
      "عینی زیدی کا لڑکیوں کو دیر سے شادی کرنے کا مشورہ\n",
      "ایشوریا رائے کا ہراسانی کیخلاف اٹھ کھڑے ہونے کا پیغام\n",
      "طلاق کے بعد میرے متعلق صرف جھوٹ بولا گیا، سمانتھا پربھو\n",
      "چندی گڑھ: گلوکار بادشاہ کے کلب کے باہر دو دھماکے\n",
      "صرف 15 کروڑ میں بنی فلم کا بزنس 900 کروڑ سے زائد، یہ فلم کونسی ہے؟\n",
      "آپ آئے تھے! دلجیت کو بالی ووڈ اداکارہ نے حیرت زدہ کردیا\n",
      "ویویک اوبرائے نے 12 کروڑ مالیت کی رولز رائس خرید لی\n",
      "انفیکشن کے باعث میری دائیں آنکھ کی بینائی ضائع ہوگئی، ایلٹن جان کا انکشاف\n",
      "ریما خان اور طارق شہاب کی شادی کو 13برس مکمل، شاندار تقریب منعقد\n",
      "ملائکہ اروڑہ کی زندگی میں تیسرے شخص کی انٹری؟\n",
      "شادی صدیوں پرانی اور بے کار روایت ہے: جاوید اختر\n",
      "انور مقصود اور انکی اہلیہ نے معین اختر کی یادیں تازہ کر دیں\n",
      "امیتابھ بچن نے 90 کروڑ روپے کا قرض کیسے ادا کیا؟\n",
      "نصرت فتح علی خان کا ذکر آتے ہی دلجیت دوسانجھ کی نگاہیں جھک جاتی ہیں: سہیل احمد\n",
      "’اے آر رحمٰن پر جھوٹے الزامات لگانا بند کریں‘، سائرہ بانو نے طلاق لینے کی وجہ بتا دی\n",
      "رشی کپور نے سانوریا کی ناکامی کی پیشگوئی کی تھی، رنبیر کپور\n",
      "پہلی فلم کے بعد بے روزگار ہونے والے الو ارجن کا کیریئر کس نے بچایا؟\n",
      "دبنگ میں کاسٹنگ نے ’ارینج میرج‘ جیسا احساس دیا، سوناکشی سنہا\n",
      "نین تارا اور شوہر کو ریسٹورنٹ میں ڈنر کیلئے آدھا گھنٹہ لائن میں لگنا پڑا\n",
      "پنت کی ریکارڈ رقم میں نیلامی کے بعد اروشی روٹیلا کی مبہم پوسٹ\n",
      "جاوید اختر نے ’اینیمل‘ پر اپنے بیان کی وضاحت کردی\n",
      "ارجن کپور سے تعلق پر ملائیکہ اروڑا کی مخفی پوسٹ\n",
      "علیحدگی کی افواہوں کے باوجود ابھیشیک نے ایشوریا کی تعریف کردی\n",
      "اپنے سابق کو مہنگے تحائف دینا مضحکہ خیز اقدام تھا، سمانتھا پربھو\n",
      "ملکۂ ترنم نور جہاں کے پوتے سکندر رضوی رشتۂ ازدواج میں منسلک\n",
      "میری طلاق سے بچوں کو مشکلات کا سامنا کرنا پڑا: جاوید شیخ کا اعتراف\n",
      "پانچ کروڑ معاوضے والی بات غلط ہے، راجکمار راؤ\n",
      "میری اہلیہ گلوکار کشور کمار کے بارے میں کچھ نہیں جانتیں، رنبیر کپور\n",
      "کرینہ کپور اپنے کزن کی روکا کی تقریب میں توجہ کا مرکز بن گئیں\n",
      "صاحبہ نے والدہ سے دوری کیوں اختیار کرلی؟ نشو بیگم نے لائیو شو میں روتے ہوئے وجہ بتا دی\n",
      "اے آر رحمان کی بہتان تراشی کرنے والوں کو قانونی کارروائی کی دھمکی\n",
      "ایشوریہ ہر جگہ آرادھیا کو ساتھ کیوں لے جاتی ہیں؟\n",
      "کیا نیلم کبھی گووندا کیساتھ ریلیشن شپ میں تھیں؟ اداکارہ کی لب کشائی\n",
      "بالی ووڈ کا ’بدقسمت ترین‘ فلم ٹائٹل، 9 فلمیں فلاپ، فلم ساز دیوالیہ ہوگئے\n",
      "سارہ علی خان تقریب سے واپسی پر اپنی گاڑی بھول کر دوسری گاڑی میں بیٹھنے لگیں\n",
      "ماہر ڈاکٹروں نے نوجوت سنگھ سدھو کا طریقہ علاج غیر ثابت شدہ قرار دیدیا\n",
      "علیزہ سلطان نے فیروز خان اور انکی نئی اہلیہ کو بچوں کے معاملے پر آڑے ہاتھوں لے لیا\n",
      "نوجوان گندی ویڈیو نہ بنائیں اور نہ اسے وائرل کریں: چاہت فتح علی خان\n",
      "پاکستانی پہلی اینیمیٹڈ فلم ’دی گلاس ورکر‘ 97 ویں آسکرز اہلیت فہرست میں شامل\n",
      "شہرت سے ڈر لگتا ہے کہ اللّٰہ کو کیا جواب دوں گی: ہانیہ عامر\n",
      "مجھے افواہوں کا ایندھن بننے میں دلچسپی نہیں، موہنی ڈے\n",
      "اے آر رحمان سے متعلق زیر گردش افواہوں پر بیٹے کا ردعمل\n",
      "اہلیہ نے اسٹیج 4 کے کینسر کو کیسے شکست دی؟ سدھو نے بتادیا\n",
      "شاہ رخ خان کی بیٹی سہانا خان کو سوشل میڈیا پر ٹرولنگ کا سامنا\n",
      "بادشاہ نے ہانیہ عامر سے تعلق کی خبروں پر خاموشی توڑ دی\n",
      "اے آر رحمان کی بیٹی کا افواہوں اور قیاس آرائیوں پر بیان، سچائی قائم رہتی ہے، رحیمہ رحمان\n",
      "احد رضا اور رمشا خان کے بیچ کیا چل رہا ہے؟ اداکار نے وضاحت دیدی\n",
      "اے آر رحمٰن نے مجھ سے معافی مانگی: بادشاہ\n",
      "شاہ رخ کو قتل کی دھمکی دینے والے نے حساس معلومات کیسے حاصل کیں؟ پولیس نے بتادیا\n",
      "سلمان خان نے والد کی پہلی موٹر سائیکل کی جھلک دکھا دی\n",
      "نین تارا اور دھنوش نے شادی کی تقریب میں ایک دوسرے کو نظر انداز کردیا\n",
      "سلمان اور شاہ رخ مقبولیت میں ایک تیلگو اسٹار سے پیچھے رہ گئے\n",
      "گرل فرینڈز بنانے کے مقابلے میں جاوید شیخ اور شان شاہد کو میں ہرا دیتا تھا: سید نور\n",
      "فردوس جمال کے بیٹے کی یوٹیوبرز کو آخری وارننگ\n",
      "علیزے شاہ کی بولڈ ویڈیو سوشل میڈیا پر وائرل\n",
      "دھنوش نے نین تارا سے قانونی جنگ کے دوران پہلی پوسٹ شیئر کردی\n",
      "بین ایفلیک کے بعد جینیفر لوپیز کی نئی محبت انکا باڈی گارڈ؟\n",
      "بھارتی سپر اسٹار الو ارجن کی ایک فلم کا معاوضہ 300 کروڑ\n",
      "اے آر رحمان کا سائرہ بانو کے بارے میں نادر تبصرہ وائرل\n",
      "شادی کے 29 سال بعد والدین کی طلاق پر اے آر رحمٰن کے بچوں نے کیا کہا؟\n",
      "اے آر رحمٰن کی طلاق کے بعد انکی گٹارسٹ کا بھی طلاق کا اعلان\n",
      "مبینہ تشدد کیس: شوہر ماجد بشیر نے اداکارہ نرگس کا میڈیکل بوگس قرار دیدیا\n",
      "آسکر ایوارڈ یافتہ بھارتی موسیقار اے آر رحمٰن نے طلاق پر خاموشی توڑ دی\n",
      "فلموں کی ناکامی پر باتھ روم میں بیٹھ کر روتا ہوں: شاہ رخ خان کا اعتراف\n",
      "آریان خان کی بطور ہدایتکار پہلی سیریز کب ریلیز ہوگی؟\n",
      "’ایسی لڑکی سے شادی کروائیں جو مشکلات نہ پیدا کرے‘، آے آر رحمان کا پرانا انٹرویو سامنے آگیا\n",
      "سائرہ بانو کا شوہر اے آر رحمان سے شادی کے 29 سال بعد علیحدگی کا اعلان\n",
      "بین افلیک کے اے آئی کے بارے میں خیالات پر سوشل میڈیا صارفین کا اظہار حیرت\n",
      "راحت فتح علی خان اور سنجے دت کی دبئی میں ملاقات، ویڈیو وائرل\n",
      "شہریار منور دسمبر میں کس لڑکی سے شادی کرنے والے ہیں؟\n",
      "ڈیلس: استاد حامد علی خان کی جادوئی غزل نائٹ میں ڈالروں کی بارش\n",
      "آئرش گرل فرینڈ سے متعلق سوال پر عدیل حسین نے کیا کہا؟\n",
      "میرا اور اہلیہ کا اختلاف گھر کی ایک عورت کی وجہ سے ہوا: فردوس جمال\n",
      "بھارت میں شراب کی دکانیں بند کر دیں، میں شراب پر گانے بند کر دونگا: دلجیت دوسانجھ کا چیلنج\n",
      "انہوں نے بھول بھلیاں 3 سے ٹکر لے کر غلطی کردی، عامر خان\n",
      "گینگسٹر لارنس بشنوئی کا بھائی انمول بشنوئی امریکا میں زیر حراست\n",
      "شدید تلخ کلامی کے بعد جیٹھا لال نے پروڈیوسر کا گریبان پکڑ لیا\n",
      "شاہ رخ نے ابتدا میں کرن ارجن میں کام کرنے سے انکار کر دیا تھا، راکیش روشن\n",
      "اداکارہ نرگس پر مبینہ تشدد، ملزم شوہر کو شاملِ تفتیش ہونے کا حکم\n",
      "محبت کی کہانی مکمل اور جاری رکھنے کیلئے شادی نہیں کرنی چاہیے: توثیق حیدر\n",
      "کپل شرما کے شو میں صرف اپنی شرط پر واپس آیا ہوں، نوجوت سنگھ سدھو\n",
      "تھراپی کی طاقت کو سمجھ گیا ہوں ماہر ذہنی صحت کے پاس جانے سے ہچکچانا نہیں چاہیئے، عامر خان\n",
      "\t--> Successfully scraped 100 articles from 'entertainment'.\n",
      "Scraping category 'sports'...\n",
      "\t--> Found 101 articles in 'sports'.\n",
      "بنگلادیش میں آئرش ویمن ٹیم کی سائیکل رکشہ پر سیر\n",
      "چیمپئنز ٹرافی: پاکستان اپنے موقف پر قائم، آئی سی سی اجلاس کل تک ملتوی کردیا گیا\n",
      "پہلا ٹیسٹ: جنوبی افریقا کیخلاف سری لنکا پہلی اننگ میں 42 رنز پر ڈھیر\n",
      "بھارتی سیاستدان تیجاشوی یادیو کا کرکٹ ٹیم پاکستان بھیجنے کا مطالبہ\n",
      "ویرات کوہلی سے سب سے زیادہ کمائی کی ٹاپ پوزیشن چھن گئی\n",
      "گلین فلپس کا ناقابلِ یقین کیچ سوشل میڈیا پر وائرل\n",
      "چیمپئنز ٹرافی: پاکستانی حکومت کا ہائبرڈ ماڈل سے انکار، بھارت کو پاکستان آنا پڑے گا\n",
      "برازیل کے ایوارڈ یافتہ باڈی بلڈر جِم میں دل کا دورہ پڑنے سے چل بسے\n",
      "پونے میں کرکٹ میچ میں بیٹر دل کا دورہ پڑنے سے چل بسے\n",
      "میرے لیے یہ اہم ہے محنت کرتا رہوں، اس کا صلہ ملے گا، کامران غلام\n",
      "ہاکی جونیئر ایشیا کپ: پاکستان کی مسلسل دوسری کامیابی، بنگلادیش کو 0-6 سے شکست\n",
      "جمعے کا دن کرکٹ کے لیے بڑا اہم ہوگا، راشد لطیف\n",
      "ورلڈ ٹیم اسکواش چیمپئن شپ، پاکستان کی چار رکنی ٹیم کا اعلان\n",
      "جیو نیوز پوڈ کاسٹ کا آغاز، کون ہے ہمارا پہلا مہمان؟\n",
      "کھیل ایک ایسی چیز ہے جو آپ کو منشیات سے دور رکھتی ہے، شاہین آفریدی\n",
      "چیمپئنز ٹرافی: پی سی بی نے بال آئی سی سی کی کورٹ میں پھینک دی\n",
      "انٹرنیشنل کرکٹ آسان نہیں ہے: نسیم شاہ\n",
      "تیسرے ون ڈے میں زمبابوے کو شکست، پاکستان نے سیریز 1-2 سے جیت لی\n",
      "بارڈر گواسکر ٹرافی: بیو ویبسٹر آسٹریلوی ٹیسٹ اسکواڈ میں شامل\n",
      "دورۂ جنوبی افریقا، وائٹ بال ٹیم میں فخر زمان کی واپسی کا قوی امکان\n",
      "پاک زمبابوے تیسرا ون ڈے آج کھیلا جائے گا\n",
      "چیمپئنز ٹرافی پاکستان میں ہی ہوگی، محسن نقوی\n",
      "عاصم خان پی ایس اے کیپ ٹاؤن اوپن اسکواش کے کوارٹر فائنل میں پہنچ گئے\n",
      "جونیئر ہاکی ایشیا کپ: پاکستان کی چین کو 2-7 سے شکست\n",
      "زمبابوے کے شان ولیمز آئی سی سی کوڈ آف کنڈکٹ کی خلاف ورزی کے مرتکب قرار\n",
      "ویمنز انڈر 19 ٹی 20 ایشیاء کپ: پاکستانی اسکواڈ کا اعلان\n",
      "احمد دانیال اور شاہنواز دھانی زمبابوے کیخلاف جاری ون ڈے سیریز سے باہر\n",
      "گیند لگنے سے ہلاک فلپ ہیوز کی 10 ویں برسی، وجۂ موت بنے بالر شین ایبٹ جذباتی ہو گئے\n",
      "افغانستان نے پاکستان کو ہراکر انڈر 19 سیریز جیت لی\n",
      "سری لنکا اے کا دوران سیریز پاکستان سے واپس جانے کا فیصلہ، بقیہ میچز منسوخ\n",
      "کافی عرصے سے موقع کی تلاش میں تھا، ابرار احمد\n",
      "پاکستان میں شیڈول چیمپئنز ٹرافی کے مستقبل پر غور کیلئے آئی سی سی بورڈ اجلاس طلب\n",
      "بلائنڈ ٹی ٹوئنٹی ورلڈ کپ: پاکستان نے بنگلا دیش کو شکست دیدی\n",
      "دوسرا ون ڈے: پاکستان نے زمبابوے کو یکطرفہ مقابلے میں 10 وکٹوں سے ہرادیا\n",
      "انگلینڈ اور نیوزی لینڈ کی سیریز کو کرو-تھارپ ٹرافی کا نام دیدیا گیا\n",
      "بھارتی کرکٹ ہیڈ کوچ گوتم گمبھیر کو آسٹریلیا سے واپس وطن جانا پڑ گیا\n",
      "پاکستان بمقابلہ زمبابوے، دوسرا ون ڈے آج کھیلا جائے گا\n",
      "زمبابوے کیخلاف دوسرے ون ڈے کیلئے پاکستان ٹیم کا اعلان\n",
      "پاکستان کے 2 اسکوائش پلیئر کیپ ٹاؤن اوپن کا حصہ\n",
      "انڈر 19 ٹرائنگولر سیریز: پاکستان، افغانستان کل فائنل میں آمنے سامنے\n",
      "بلائنڈ ٹی 20 ورلڈ کپ: بنگلا دیش نے سری لنکا کو 25 رنز سے ہرا دیا\n",
      "بلائنڈ ٹی 20 ورلڈ کپ: نیپال نے افغانستان کو ہرا دیا\n",
      "پرتھ ٹیسٹ میں بھارت نے آسٹریلیا کو شکست دیدی\n",
      "سابق کرکٹر عبدالرزاق کا دیدار سے محبت کا اعتراف\n",
      "ویرات کوہلی نے اہم سنگ میل عبور کر لیا\n",
      "پہلا ون ڈے: ڈی ایل میتھڈ کے تحت زمبابوے کی پاکستان کو شکست\n",
      "چیمپئنز ٹرافی: منگل کو آئی سی سی کا ہنگامی اجلاس نہیں ہو گا\n",
      "پاکستان زمبابوے سیریز کا پہلا ون ڈے آج کھیلا جائے گا\n",
      "پاکستان اور زمبابوے کے درمیان پہلا ایک روزہ میچ کل، دونوں ٹیموں کا بھرپور پریکٹس سیشن\n",
      "پرتھ ٹیسٹ: آسٹریلیا کیخلاف بھارت کی پوزیشن مضبوط\n",
      "آسٹریلیا میں جو کرکٹ کھیلی، وہ اب ماضی بن چکی، محمد رضوان\n",
      "بلائنڈ ٹی ٹوئنٹی ورلڈ کپ میں پاکستانی ٹیم کا کامیاب آغاز\n",
      "چیمپئنز ٹرافی کراچی سے لاہور پہنچا دی گئی\n",
      "پرتھ ٹیسٹ: دوسرے دن کے اختتام پر بھارت کو آسٹریلیا پر 218 رنز کی برتری حاصل\n",
      "قائداعظم ٹرافی کے فائنل راؤنڈ میچز کا شیڈول تبدیل\n",
      "چیمپئنز ٹرافی معاملہ، آئی سی سی نے ہنگامی بیٹھک بلالی، بھارتی میڈیا کا دعویٰ\n",
      "چمچماتی چیمپئنز ٹرافی کی کراچی کے مختلف مقامات پر رونمائی\n",
      "چیمپئنز ٹی20 کپ 7 تا 25 دسمبر راولپنڈی میں ہوگا، پی سی بی\n",
      "بلائنڈ ٹی20 ورلڈ کپ: بھارت کی حریف ٹیموں کو واک اوور مل گیا\n",
      "بھارت اور آسٹریلیا کے ٹیسٹ میچ کے پہلے دن  17 وکٹیں گر گئیں\n",
      "مرتضیٰ وہاب اور ناصر شاہ نے چیمپئنز ٹرافی اٹھا کر پاکستان زندہ باد کا نعرہ لگا دیا\n",
      "اظہر علی پی سی بی یوتھ ڈیولپمنٹ کے سربراہ مقرر\n",
      "پاک سعودیہ ویمن فٹبال ٹیم کے مشترکہ ٹریننگ کیمپ کا پلان منسوخ\n",
      "سابق ٹیسٹ کرکٹر محمد نذیر جونیئر انتقال کر گئے\n",
      "بیٹر کا شاٹ، گیند سیدھی آسٹریلوی امپائر کے منہ پر جا لگی\n",
      "بلائنڈ T20 ورلڈ کپ، سری لنکن ٹیم پاکستان پہنچ گئی\n",
      "زمبابوے کیخلاف سیریز، پاکستان کرکٹ اسکواڈ بلاوائیو پہنچ گیا\n",
      "چیمپئنز ٹرافی کراچی پہنچ گئی، برنس روڈ فوڈ اسٹریٹ پر فوٹو شوٹ\n",
      "وائٹ بال کرکٹ ٹیم کے عبوری ہیڈ کوچ عاقب جاوید کل زمبابوے روانہ ہونگے\n",
      "پی سی بی نے گریڈ ٹو میں شریک ڈپارٹمنٹل ٹیموں کی فیس کئی گنا بڑھا دی\n",
      "فخر زمان کی ٹیم میں واپسی پر ہیڈ کوچ کا بیان سامنے آ گیا\n",
      "بھارتی بلائنڈ کرکٹ ایسوسی ایشن کا عالمی کونسل کو عدم شرکت سے متعلق خط\n",
      "چیمپئنز ٹرافی کے شیڈول کے اعلان میں مزید تاخیر کا امکان\n",
      "ٹی ٹوئنٹی بلائنڈ کرکٹ ورلڈ کپ: جنوبی افریقی ٹیم لاہور پہنچ گئی\n",
      "بھارت بلائنڈ ٹی20 ورلڈکپ سے دستبردار ہوگیا\n",
      "چیمپئنز ٹرافی کیلئے آنے میں بھارت کی ہندوتوا سوچ آڑے آ گئی:  ثناء اللّٰہ مستی خیل\n",
      "پی ایف ایف کا کانگریس اجلاس آج نہ ہو سکا\n",
      "شاہد اسلم کو پاکستان ٹیم کا بیٹنگ کوچ بنا دیا گیا\n",
      "سابق ٹیسٹ کرکٹر محمد نذیر جونیئر کی طبیعت خراب، بہترین علاج کی ضرورت\n",
      "پی سی بی کا محمد یوسف کا استعفیٰ منظور کرنے سے انکار\n",
      "بیٹنگ میں اچھے آغاز کا فائدہ نہیں اٹھا سکے، سلمان علی آغا\n",
      "پی سی بی نے ویمن نیشنل کپ کے باقی میچز منسوخ کردیے\n",
      "ہمارے پاس مڈل آرڈر میں تجربہ کار بیٹر نہیں، محمد رضوان\n",
      "پاکستان کیخلاف زمبابوے کا ون ڈے اور ٹی ٹوئنٹی اسکواڈ کا اعلان\n",
      "کپتان محمد رضوان نے تیسرا ٹی20 کیوں نہیں کھیلا؟ وجہ سامنے آگئی\n",
      "کراچی: مقامی ہوٹل میں آتشزدگی کے سبب ویمن نیشنل ون ڈےکپ ملتوی\n",
      "چیمپئنز ٹرافی میں بھارت کے نہ آنے پر اپنے مؤقف پر قائم ہیں اور رہینگے: چیئرمین پی سی بی محسن نقوی\n",
      "سال بھر قبل مایوس ہو کر کرکٹ چھوڑ دی تھی: جہانداد خان\n",
      "آسٹریلیا نے پاکستان کو تیسرے ٹی ٹوئنٹی میں بھی شکست دیدی\n",
      "آسٹریلیا کیخلاف تیسرا ٹی 20، محمد رضوان پلیئنگ الیون سے باہر\n",
      "محمد رضوان کا سڈنی کرکٹ گراؤنڈ میوزیم کو کیپنگ گلوز اور شرٹ کا عطیہ\n",
      "تیسرا T20، وائٹ واش سے بچنے کیلئے شاہین کینگروز کے شکار کو تیار\n",
      "جیسن گلیسپی ہی پاکستان ریڈ بال کرکٹ ٹیم کی کوچنگ کریں گے ، پی سی بی\n",
      "علی حیدر نے انجری کے باوجود بنکاک میراتھون مکمل کرلی\n",
      "وائٹ بال کرکٹ ٹیم کے ہیڈ کوچ کی ذمے داریاں عاقب جاوید کو ملنے کا امکان\n",
      "محمد یوسف سلیکشن کمیٹی کے بعد کوچنگ سے بھی الگ ہوگئے\n",
      "وہاب ریاض کو ایک بار پھر بورڈ میں ذمے داریاں دیے جانے کا امکان\n",
      "چیمپئنز ٹرافی معاملہ: آئی سی سی کا پاکستان سے ناروا سلوک عیاں ہوگیا\n",
      "پاکستان کے حسن عثمانی نے اشک آباد اوپن ٹینس ٹورنامنٹ جیت لیا\n",
      "\t--> Successfully scraped 99 articles from 'sports'.\n",
      "Scraping category 'world'...\n",
      "\t--> Found 100 articles in 'world'.\n",
      "اسرائیل کی غزہ میں نئی یہودی بستی قائم کرنے کی تیاری، سیٹلائٹ امیج نے بھانڈا پھوڑ دیا\n",
      "پاکستانی طالبعلم کی ایران میں بھارتی مسافر کی مدد، کہانی وائرل\n",
      "حماس کی جانب سے رہا کی گئی اسرائیلی لڑکی نے منگنی کر لی\n",
      "روسی صدر پیوٹن کی انجیلا مرکل کو کتے سے ڈرانے کی تردید\n",
      "چین میں دنیا کا سب سے بڑا سونے کا ذخیرہ دریافت\n",
      "یوکرین کو جوہری ہتھیار ملے تو تمام فوجی وسائل استعمال کرینگے: پیوٹن\n",
      "ایران کو جوہری بم حاصل کرنے سے روکنے کیلئے سب کچھ کریں گے: نیتن یاہو\n",
      "غزہ میں مکمل جنگ بندی کا مطالبہ کرتے ہیں، سیکرٹری خارجہ آمنہ بلوچ\n",
      "یوگنڈا کے مرکزی بینک سے ہیکرز نے ایک کروڑ 70 لاکھ ڈالر چرالیے\n",
      "اسرائیلی جارحیت کے دوران 3823 افراد جاں بحق، 15 ہزار سے زائد زخمی، لبنانی وزارت صحت\n",
      "جرمن صحافیوں کی ماسکو سے بیدخلی، روسی سفیر دفتر خارجہ طلب\n",
      "لبنان: صدر کے انتخاب کیلئے پارلیمانی سیشن 9 جنوری 2025ء کو طلب\n",
      "روس نے توانائی تنصیبات کو کلسٹر امیونیشنز سے نشانہ بنایا: یوکرینی صدر زیلنسکی\n",
      "ملائیشیا: بارشوں سے 6 ریاستوں میں سیلاب، 37 ہزار افراد متاثر\n",
      "پاکستان نے یورپین پارلیمنٹ جنوبی ایشین ڈیلی گیشن کے سامنے مؤقف رکھ دیا\n",
      "جنوبی کوریا: سیؤل میں دوسرے روز بھی ریکارڈ برفباری، 5 افراد ہلاک\n",
      "آئندہ 5 سال کیلئے نئے یورپین کمشنرز کی توثیق\n",
      "امریکا جاپان میں میزائل نصب کرنے سے باز رہے، روس کا انتباہ\n",
      "امریکا و چین کا 3، 3 قیدیوں کا تبادلہ\n",
      "مسجد الحرام، مسجدِ نبویؐ سمیت سعودیہ بھر میں نماز استسقاء ادا\n",
      "ریاض میٹرو پروجیکٹ کا افتتاح\n",
      "آسٹریلیا: کم عمر بچوں پر سوشل میڈیا کے استعمال کی پابندی کا بل منظور\n",
      "یوکرین: کئی شہر صبح سویرے دھماکوں سے گونچ اٹھے\n",
      "ٹرمپ نے ریٹائرڈ جنرل کیتھ کیلوگ کو روس اور یوکرین کیلئے مندوب مقرر کردیا\n",
      "جنگ بندی کے باوجود اسرائیلی فوج نے جنوبی لبنان میں کرفیو نافذ کردیا\n",
      "ٹرمپ نے حلف اُٹھانے سے پہلے ہی کینیڈا سے تعلقات خراب کرنا شروع کردیے\n",
      "بھارتی خاتون پائلٹ کی خودکشی، بوائےفرینڈ گرفتار\n",
      "حزب اللّٰہ کا حسن نصراللّٰہ کا جسد خاکی شایان شان انداز میں سپرد خاک کرنے کا اعلان\n",
      "برطانیہ: کردستان ورکرز پارٹی سے تعلق کا الزام، 6 افراد گرفتار\n",
      "غزہ پر اسرائیلی جارحیت کیخلاف کیمبرج یونیورسٹی کے طلبا کا احتجاج\n",
      "مصنف و شاعر بریتین بریتن باخ پیرس میں چل بسے\n",
      "برطانیہ: عورت کی قانونی تعریف کا تنازع عدالت پہنچ گیا\n",
      "جنوبی کوریا: سیؤل میں ریکارڈ برفباری، 2 افراد ہلاک، 200 پروازیں معطل\n",
      "چینی وزیرِ دفاع کیخلاف کرپشن کی تحقیقات شروع\n",
      "بھارت: گوگل کے بتائے راستے پر چلنے سے 3 افراد جان گنوا بیٹھے\n",
      "لبنان کے بعد غزہ میں بھی جنگ بندی کیلئے تیار ہیں: حماس\n",
      "اسرائیل سے جنگ بندی کے بعد لبنانی گھروں کو لوٹنا شروع\n",
      "برطانوی وزیرِ اعظم کا اسرائیل اور حزب اللّٰہ کے درمیان جنگ بندی کا خیرمقدم\n",
      "ڈونلڈ ٹرمپ کو میکسیکو کی صدر کلاڈیا شین بام کی جوابی دھمکی\n",
      "امریکی صدر کا اسرائیل اور حزب اللّٰہ کے درمیان جنگ بندی کا اعلان\n",
      "اسرائیلی کابینہ نے لبنان جنگ بندی معاہدے کی منظوری دے دی\n",
      "سابق امریکی ڈائریکٹر نیشنل انٹیلی جنس کا بانی پی ٹی آئی کی رہائی کا مطالبہ\n",
      "ٹرمپ کیخلاف 6 جنوری کیس ختم ہوگیا\n",
      "برطانیہ میں امریکی اڈوں پر ایک بار پھر نامعلوم ڈرونز کی پروازیں، نگرانی جاری\n",
      "‎فلسطینیوں کیلئے انروا کے اقدامات کی حمایت اور اسرائیلی جنگی جرائم کے احتساب کا مطالبہ کرتے ہیں، پاکستان\n",
      "روس طالبان تعلقات کی جانب اہم قدم، روسی پارلیمنٹ میں دہشتگرد تنظیموں پر عائد پابندی اٹھانے کا بل پیش\n",
      "مصر: سیاحوں کی کشتی ڈوب گئی، 16 مسافر لاپتہ\n",
      "روس کی کالعدم تنظیموں کی فہرست سے طالبان کو نکالنے کی یقین دہانی\n",
      "سعودی عرب: مختلف شہروں میں بارش کا امکان\n",
      "جو بائیڈن کا ٹرمپ کی تقریبِ حلف برداری میں شرکت کا فیصلہ\n",
      "برطانیہ میں بارشیں، طوفانی ہواؤں سے ہیتھرو ایئر پورٹ پر طیارہ ڈگمگا گیا\n",
      "کینیڈا: 2 پاکستانی نژاد اونٹاریو لبرل پارٹی کے صوبائی امیدوار منتخب\n",
      "انڈونیشیا: شدید بارشیں، سیلاب، لینڈ سلائیڈنگ، 15 افراد ہلاک\n",
      "اسرائیل لبنان 60 روزہ جنگ بندی معاہدہ طے، جلد جنگ ختم ہونے کا امکان\n",
      "ڈونلڈ ٹرمپ کا میکسیکو، کینیڈا، چین سے آئی اشیاء پر بھاری ٹیکس لگانے کا اعلان\n",
      "نومنتخب صدر ڈونلڈ ٹرمپ کیخلاف 6 جنوری کا کیس ختم\n",
      "یو اے ای میں اسرائیلی ربی کے قتل میں ملوث ملزمان کی شناخت ظاہر کردی گئی\n",
      "لبنان میں جنگ بندی پر اتفاق طے پا گیا ہے، اسرائیلی میڈیا\n",
      "ڈونلڈ ٹرمپ کی پوتی کائی ٹرمپ  کی رقص کرتی ویڈیو وائرل\n",
      "مکہ مکرمہ اور دیگر علاقوں میں موسلا دھار بارش، سڑکیں زیر آب\n",
      "اسرائیلی وزیراعظم کی گرفتاری نہیں، موت کی سزا کا حکم دینا چاہیے، آیت اللّٰہ خامنہ ای\n",
      "بنگلادیشی عبوری حکومت کیخلاف احتجاج کرنے والا ہندو مذہبی رہنما ڈھاکا ایئرپورٹ پر گرفتار\n",
      "نیتن یاہو برطانیہ آئے تو عالمی عدالت کے فیصلے پر کارروائی کریں گے، ڈیوڈ لیمی\n",
      "خالصتان کے قیام تک جدوجہد جاری رہے گی، فرانس میں سکھ رہنماؤں کا احتجاج سے خطاب\n",
      "ایران جوہری پروگرام پر مغرب کیساتھ بات چیت کیلئے رضامند\n",
      "بھارت: ہندو انتہا پسندوں کا مسجد کی جگہ مندر بنانے کا دعویٰ، ہنگاموں میں 5 افراد ہلاک\n",
      "لیتھوانیا: کارگو طیارہ لینڈنگ سے قبل گر کر تباہ\n",
      "برطانیہ: برٹ طوفان سے نظامِ زندگی درہم برہم، 5 افراد ہلاک\n",
      "ایران نے متحدہ عرب امارات میں اسرائیلی ربی کے قتل کا الزام مسترد کر دیا\n",
      "تل ابیب، بن گورین ایئرپورٹ پر فلائٹ آپریشن عارضی معطل\n",
      "یو اے ای میں یہودی ربی کا قتل، شبے میں 3 افراد گرفتار\n",
      "ایران اسرائیل کے حملوں کا جواب دینے کی تیاری کر رہا ہے، علی لاریجانی\n",
      "بھارت: ایک اور مسجد پر مندر کا دعویٰ، ہنگامے پھوٹ پڑے، پولیس فائرنگ سے تین افراد جاں بحق\n",
      "پیرس: سکھ برادری کا احتجاج، بھارت سے اقلیتوں پر مظالم فوری بند کرنے کا مطالبہ\n",
      "پیرس: پی ٹی آئی فرانس کا احتجاجی مظاہرہ، بانی و دیگر رہنماؤں کی رہائی کا مطالبہ\n",
      "بھارت: زیر تعمیر پل سے کار دریا میں گرنے سے 3 نوجوان ہلاک\n",
      "تحریک انصاف بیلجیئم کے زیر اہتمام  یورپی پارلیمنٹ کے سامنے احتجاجی مظاہرہ\n",
      "دبئی میں لاپتہ اسرائیلی ربی کی لاش کی شناخت، مالدووا کا پاسپورٹ برآمد\n",
      "نیتن یاہو، فوج اور انٹیلیجنس ایجنسیز میں اختلافات سامنے آگئے\n",
      "طوفان برٹ برطانیہ سے ٹکرا گیا، حادثات میں 2 افراد ہلاک\n",
      "متحدہ عرب امارات میں اسرائیلی شہری لاپتا، اسرائیلی وزیراعظم دفتر\n",
      "برسلز، منتخب کونسلرز کا مسائل مل کر حل کرنے کا فیصلہ\n",
      "ڈونلڈ ٹرمپ کی جینیٹ نیشیوات کی بطور سرجن جنرل نامزدگی\n",
      "آسٹریلیا، بچوں پر سوشل میڈیا کے استعمال کی پابندی کا بل پیش\n",
      "لبنان میں داخل ہونے والے اسرائیلی ماہر آثارِ قدیمہ حزب اللّٰہ کے حملے میں ہلاک\n",
      "یوکرین کے شہر سومی پر روس کا ڈرون حملہ، 2 افراد ہلاک، 12 زخمی\n",
      "امریکا: بھارتی طالب علم اپنی سالگرہ کے موقع پر گولی چلنے سے ہلاک\n",
      "بابا صدیق قتل کیس: قاتلوں کی مالی اعانت کرنے والا شخص گرفتار\n",
      "نیتن یاہو اور گیلنٹ کیلئے دنیا تنگ، 124ممالک عدالتی احکامات پر عملدرآمد کے پابند\n",
      "امریکا میں پھیپھڑوں کی پہلی اور کامیاب روبوٹک پیوندکاری\n",
      "مہنگائی میں کمی، کینیڈا میں دو ماہ کیلئے کھانے پینے کی اشیا پر ٹیکس معاف\n",
      "لندن میں امریکی سفارت خانے کے باہر مشتبہ پیکٹ ملنے کے بعد سیکیورٹی الرٹ\n",
      "بھارتی بحریہ کی آبدوز ماہی گیروں کی کشتی سے ٹکرا گئی\n",
      "کرم میں دہشتگردی، ایرانی صدر کا اظہارِ تعزیت\n",
      "روس نے یوکرین کو ہتھیاروں کی تجربہ گاہ سمجھ لیا: یوکرینی صدر زیلنسکی\n",
      "امریکا، میٹ گیٹز اٹارنی جنرل کے عہدے کی نامزدگی سے دستبردار\n",
      "تدمر میں اسرائیلی فوج کا حملہ، 79جاں بحق\n",
      "دوست کو شادی کا تحفہ دیتے ہوئے نوجوان چل بسا\n",
      "\t--> Successfully scraped 98 articles from 'world'.\n",
      "Scraping category 'health-science'...\n",
      "\t--> Found 102 articles in 'health-science'.\n",
      "پاکستان میڈیکل اینڈ ڈینٹل کونسل کا ڈینٹل ڈگری بھی 5 سالہ کرنے کا فیصلہ\n",
      "کھانے کے بعد صرف 5 منٹ کی چہل قدمی سے صحت بہتر\n",
      "تین برسوں میں دمہ کے طریقہ علاج میں بڑی تبدیلی متوقع ہے، برطانوی سائنسدان\n",
      "موسمِ سرما میں جلد اور بالوں کی حفاظت کیسے کریں؟\n",
      "کوئٹہ: سرکاری اسپتالوں میں گرینڈ ہیلتھ الائنس کی علامتی ہڑتال جاری\n",
      "ایک اور بچہ پولیو سے متاثر، مجموعی تعداد 56 ہوگئی\n",
      "دنیا میں 40 برس میں گزشتہ سال ایڈز کے سب سے کم کیسز رپورٹ\n",
      "کوئٹہ: سرکاری اسپتالوں میں گرینڈ ہیلتھ الائنس کی کال پر ہڑتال کا تیسرا روز\n",
      "موسمِ سرما اور ڈپریشن میں کیا تعلق ہے؟\n",
      "صحت مند رہنے کیلئے کونسی چکنائی ضروری؟\n",
      "نمونیا و ہیپاٹائٹس کی ادویات فراہمی کیس، ڈرگ ریگولیٹری اتھارٹی سے رپورٹ طلب\n",
      "کیلا ہی نہیں اس سے تیار کردہ چائے بھی بے حد مفید\n",
      "پاکستان میں پولیو سے مزید 3 بچے متاثر، تعداد 55 ہوگئی\n",
      "بلوچستان، محکمہ صحت میں ڈاکٹرز کی ساڑھے 3 ہزار پوسٹیں خالی ہونے کا انکشاف\n",
      "پنجاب: اسموگ سے مزید 61 ہزار افراد پھیپھڑوں کے امراض میں مبتلا\n",
      "نہار منہ کن پھلوں کا استعمال کیا جا سکتا ہے؟\n",
      "مریضوں میں ایچ آئی وی کی منتقلی، نجی اسپتالوں کو احکامات جاری کردیے\n",
      "امریکا میں پھیپھڑوں کی پہلی اور کامیاب روبوٹک پیوندکاری\n",
      "دماغی فالج کا علاج ممکن ہے؟\n",
      "پاکستان میں مزید 2 بچے پولیو سے متاثر، تعداد 52 ہو گئی\n",
      "سندھ: جنوری تا اکتوبر ایڈز کے 2531 کیسز رپورٹ\n",
      "خیبرپختونخوا: رواں سال خناق سے 20 بچے جاں بحق\n",
      "دن کی نیند ضعیف افراد میں ڈیمنشیا کا باعث\n",
      "پانچ منٹ کے آسان ڈرائنگ ٹیسٹ سے ڈیمنشیا کی علامات کا پتا لگایا جاسکتا ہے، ماہرین\n",
      "کے پی: 92 ہزار بچے گھروں پر نہ ہونے سے پولیو ویکسین قطروں سے محروم رہے\n",
      "فضائی آلودگی سے پریشان ہیں تو زیتون کے پتوں کی بھاپ لیجیے\n",
      "پی ایم ڈی سی کی میڈیکل اور ڈینٹل کالجز میں اینٹی ہراسمنٹ کمیٹیاں بنانے کی ہدایت\n",
      "ناریل پانی کس موسم میں اور کس وقت زیادہ مؤثر؟\n",
      "کوہاٹ: دو بچوں میں پولیو وائرس کی تصدیق\n",
      "دن میں ساڑھے 10 گھنٹوں سے زیادہ بیٹھنا دل کیلئے نقصاندہ اور خطرناک ہوتا ہے، ماہرین\n",
      "نشتر اسپتال ملتان میں ایڈز منتقلی کی تحقیقات مکمل، رپورٹ سیکریٹری ہیلتھ کو پیش\n",
      "اینٹی مائیکروبیل ریزسٹنس سے نمٹنے کیلئے نیشنل ایکشن پلان ٹو تیار\n",
      "ملتان: نشتر اسپتال میں ڈائیلسز کے نئے مریضوں کے علاج پر پابندی\n",
      "پُرکشش دکھائی دینا ہے تو دن کا آغاز صحت بخش ناشتے سے کیجیے\n",
      "کیا کھانے کی خواہش ذہنی صحت پر اثرانداز ہوتی ہے؟\n",
      "ملتان: نشتر اسپتال میں ڈائیلسز کے رجسٹرڈ مریضوں کا ایک سال سے ایڈز ٹیسٹ نہ ہونے کا انکشاف\n",
      "ملتان: نشتر اسپتال میں 25 مریضوں میں ایڈز وائرس منتقل ہونے کی تصدیق\n",
      "کافی کے صحت پر حیرت انگیز فائدے، پھر بھی احتیاط ضروری\n",
      "پنجاب میں اسموگ کے باعث 19 لاکھ سے زائد افراد اسپتال پہنچ گئے\n",
      "تھوڑا آرام اپنے پیروں اور ایڑیوں کو بھی دیں\n",
      "ڈیمینشیا کی علامات برسوں پہلے ظاہر ہونا شروع ہوجاتی ہیں، تحقیق\n",
      "بلوچستان کے ضلع جعفر آباد سے پولیو کیس رپورٹ، تعداد 49 ہوگی\n",
      "سورج کی روشنی، دودھ اور مچھلی کے استعمال سے وٹامن ڈی کی کمی پوری ہوسکتی ہے، ماہرین\n",
      "بلوچستان میں پولیو کا ایک اور کیس رپورٹ\n",
      "سینیٹر فوزیہ ارشد کی ڈریپ ایکٹ میں ترمیم کی حمایت\n",
      "ملتان: نشتر اسپتال میں مریضوں میں ایڈز پھیلنے کی وجہ سامنے آ گئی\n",
      "پاکستان سمیت آج دنیا بھر میں ذیابیطس کا عالمی دن منایا جارہا ہے\n",
      "148 دن میں ساڑھے 53 لاکھ مریضوں کا انکی دہلیز پر علاج کیا گیا: مریم نواز\n",
      "ملتان: نشتر اسپتال میں 30 مریض ایڈز میں مبتلا\n",
      "گلے میں خراش یا سوزش ہے تو چند آزمودہ نسخے آپ کیلئے\n",
      "کراچی: مبینہ غلط انجکشن سے 3 سالہ بچی کا انتقال\n",
      "اسموگ سے بچوں کے پھپھڑے اور دماغی نشوونما متاثر ہو رہے ہیں: عالمی ادارۂ اطفال کا انتباہ\n",
      "بال خوبصورت، لمبے اور گھنے بنائیں گھر پر تیار شیمپو سے\n",
      "روزانہ کی خوراک سے صرف ایک گرام نمک کم کرنے کے فوائد\n",
      "رواں سال کراچی میں ڈینگی کے 1 ہزار 843 کیسز\n",
      "سندھ: رواں سال ڈینگی کے 2 ہزار 192 کیسز رپورٹ\n",
      "موسمبی سے صحت بھی، خوبصورتی بھی\n",
      "پنجاب میں ڈینگی کے 79 کیسز رپورٹ\n",
      "خوشی حاصل کرنے کی خواہش کا ڈوپامین سے کیا تعلق؟ اسے کنٹرول کیسے کریں؟\n",
      "لاہور میں اسموگ کی شدت برقرار، بیماریاں پھیلنے لگیں\n",
      "پاکستان میں 48ویں پولیو وائرس کیس کی تصدیق\n",
      "انسانوں کی عمر کتنی طویل ہو سکتی ہے؟ سائنسدانوں نے پتہ لگا لیا\n",
      "ایم ڈی کیٹ کے ہی مخالف ہوں: ڈاکٹر عذرا فضل پیچوہو\n",
      "قوتِ برداشت میں کمی محسوس ہو تو کیا کریں؟\n",
      "کونسی غذائیں ڈپریشن کم کرتی ہیں؟\n",
      "کوئٹہ: ادویات چھپانے پر 3 فارماسسٹس گرفتار، 2 کی تلاش جاری\n",
      "پنجاب: اسموگ سے آنکھ، ناک، کان، گلے کی بیماریاں پھیلنے لگیں\n",
      "ملک میں ایک اور پولیو کیس کی تصدیق، تعداد 46 ہو گئی\n",
      "بلوچستان: وزیرِ اعلیٰ کا انسدادِ پولیو کیلئے 10 روز میں جامع روڈ میپ مرتب کرنے کا حکم\n",
      "بلوچستان میں انسدادِ پولیو مہم اختتام پزیر، 99 فیصد ہدف حاصل\n",
      "پنجاب: ڈینگی کے مزید 118 کیسز رپورٹ\n",
      "خناق کیا ہے، بچاؤ کیلئے ویکسینیشن کیوں ضروری؟\n",
      "دادو: 7 سالہ بچی میں پولیو وائرس کا شبہ، کراچی کے اسپتال منتقل\n",
      "پنجاب بھر میں ڈینگی کیسز کے اعداد و شمار جاری\n",
      "51 فیصد افراد کے اینٹی بائیوٹک ادویات از خود استعمال کرنے کا انکشاف\n",
      "پنجاب میں ڈینگی وائرس کے مزید 141 کیسز رپورٹ\n",
      "کراچی: اکتوبر میں ڈینگی کے 363 کیسز رپورٹ\n",
      "ورزش سے قبل درست غذاؤں کا انتخاب کیوں ضروری؟\n",
      "ملک میں پولیو وائرس کے مزید دو کیسز سامنے آگئے\n",
      "بینائی کی حفاظت آپ کے ہاتھوں میں، اس کا خیال رکھیں\n",
      "گزشتہ برس دنیا بھر میں تپ دق کے 82 لاکھ نئے کیسز کی تشخیص ہوئی، عالمی ادارہ صحت\n",
      "اسلام آباد میں چکن گونیا کا پہلا تصدیق شدہ کیس رپورٹ\n",
      "پاکستان میں تپِ دق کے کیسز میں نمایاں اضافہ\n",
      "وزن کم کرنے کیلئے ورزش سے قبل کیا کھائیں اور کیا نہیں؟\n",
      "اورکزئی: حملے کے بعد رکی انسدادِ پولیو مہم کا آج سے دوبارہ آغاز\n",
      "بلوچستان: رواں سال پولیو کے 21 کیسز رپورٹ ہوئے\n",
      "ڈینگی پھیلانے والا مچھر ہی چکن گونیا کا باعث بنتا ہے، ماہرین\n",
      "گورنر سندھ کی ملیریا کے کیسز میں اضافے پر ایکشن کی ہدایت\n",
      "بلوچستان میں انسدادِ پولیو مہم جاری\n",
      "سندھ بھر میں ملیریا کے کیسز میں مسلسل اضافہ\n",
      "موبائل کا غلط انداز میں استعمال ذہنی مسائل کا سبب بن سکتا ہے، تحقیق\n",
      "پنجاب حکومت کا 150 بنیادی مراکز صحت آؤٹ سورس کرنے کافیصلہ\n",
      "کے پی کے: ڈینگی کے مزید 56 کیسز رپورٹ\n",
      "پولیو قطرے پلانے سے انکار کرنیوالے 50 فیصد لوگوں کی نشاندہی کر لی: مراد علی شاہ\n",
      "کے پی کے: 33 اضلاع میں 5 روزہ انسدادِ پولیو مہم کا پہلا مرحلہ شروع\n",
      "ایک سیب روزانہ، واقعی رکھے ڈاکٹر سے دور؟\n",
      "سندھ: 7 روزہ انسدادِ پولیو مہم کا آغاز آج ہو گا\n",
      "سندھ بھر میں سات روزہ انسداد پولیو مہم کا آغاز کل سے ہوگا، ایمرجنسی آپریشن سینٹر\n",
      "لاہور میں آلودگی سے بیماریاں پھیلنے لگیں\n",
      "پولیو سے نمٹنے کیلئے پاکستان و دیگر ممالک میں سعودی منصوبوں پر عملدرآمد\n",
      "\t--> Successfully scraped 100 articles from 'health-science'.\n",
      "Scraping category 'business'...\n",
      "\t--> Found 56 articles in 'business'.\n",
      "اسٹاک ایکسچینج میں آج بھی زبردست تیزی، انڈیکس 1274 پوائنٹس بڑھ گیا\n",
      "پیٹرول، ڈیزل کی قیمتیں آئندہ 15 روز کیلئے برقرار رکھنے کا امکان\n",
      "سونا سستا ہو گیا، آج قیمت کتنی کم ہوئی؟\n",
      "گرے مارکیٹ کے دوبارہ وجود نے سال 2023 کی یادیں تازہ کردیں\n",
      "انٹر بینک مارکیٹ میں ڈالر کے مقابلے میں روپے کی قدر مزید 10 پیسے بہتر ہوئی\n",
      "انٹر بینک میں ڈالر کے مقابلے میں پاکستانی روپے کی قدر میں اضافہ\n",
      "امریکا میں نو منتخب صدر ڈونلڈ ٹرمپ کے ’ٹیرف نفاذ‘ سے ایشیا کو سستا خام تیل ملنے کا امکان\n",
      "اسٹاک ایکسچینج میں نئی تاریخ رقم، 100 انڈیکس ایک لاکھ پوائنٹس کا سنگ میل عبور کرگیا\n",
      "ٹی بلز پر منافع میں مزید کمی، حکومت نے 12 کھرب روپے اکٹھے کرلیے\n",
      "نیپرا کا فی یونٹ ٹیرف میں ایک روپے 60 پیسے کمی کا تخمینہ\n",
      "ملک میں 2030 تک 30 فیصد گاڑیاں الیکٹرک پر منتقل کرنے کیلئے نئی پالیسی کا اعلان\n",
      "’پاکستان کو 2050 تک کاربن کے کم اخراج کی طرف منتقلی کیلئے 390 ارب ڈالر درکار ہیں‘\n",
      "اپٹما کا حکومت سے آئی ایم ایف کےساتھ گیس کی بندش پر دوبارہ گفت و شنید کا مطالبہ\n",
      "گوتم اڈانی پر امریکا میں فرد جرم کے بعد ایک ہفتے میں ’اڈانی گروپ‘ کو 55 ارب ڈالر کا نقصان\n",
      "ملک بھر میں سونے کی قیمتوں میں اضافہ\n",
      "اسٹاک ایکسچینج میں آج بھی زبردست تیزی، انڈیکس 1274 پوائنٹس بڑھ گیا\n",
      "پیٹرول، ڈیزل کی قیمتیں آئندہ 15 روز کیلئے برقرار رکھنے کا امکان\n",
      "امریکا میں نو منتخب صدر ڈونلڈ ٹرمپ کے ’ٹیرف نفاذ‘ سے ایشیا کو سستا خام تیل ملنے کا امکان\n",
      "ٹی بلز پر منافع میں مزید کمی، حکومت نے 12 کھرب روپے اکٹھے کرلیے\n",
      "وزارت خزانہ نے ملک میں معاشی سرگرمیوں میں مزید اضافے کی پیش گوئی کردی\n",
      "اسٹاک مارکیٹ میں نئی تاریخ رقم، ایک ہی دن انڈیکس میں 4 ہزار 695 پوائنٹس کا ریکارڈ اضافہ\n",
      "سونا سستا ہو گیا، آج قیمت کتنی کم ہوئی؟\n",
      "ملک بھر میں سونے کی قیمتوں میں اضافہ\n",
      "سونے کی قیمتوں میں اضافہ رک گیا، آج فی تولہ نرخوں میں بڑی کمی\n",
      "سونے کی قیمتوں میں مسلسل چھٹے روز اضافہ، مزید 2200 روپے مہنگا ہوگیا\n",
      "اسٹیٹ بینک نے بینکوں کے لیے کم سے کم ڈپازٹ شرح (ایم ڈی آر) کی شرط ختم کردی\n",
      "نیٹ میٹرنگ کو ونٹر پیکیج سے نکالنے پر حکومت کو تنقید کا سامنا\n",
      "کم شرح سود کے باعث آٹو فنانسنگ میں مسلسل دوسرے ماہ اضافہ\n",
      "سیاسی کشیدگی سے اسٹاک مارکیٹ کریش، 100 انڈیکس 3 ہزار 505 پوائنٹس گرگیا\n",
      "سونے کی فی تولہ قیمت میں آج بھی بڑی کمی\n",
      "90 فیصد بینکرز سائبر کرائمز کو سب سے بڑا خطرہ سمجھتے ہیں، رپورٹ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247206/\n",
      "سونے کی قیمتوں میں اضافہ رک گیا، آج فی تولہ نرخوں میں بڑی کمی\n",
      "پاکستان اور بیلاروس میں تجارت کے فروغ کیلئے8 مفاہمتی یادداشتوں اور معاہدوں پر دستخط\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247154/\n",
      "اسٹاک مارکیٹ میں مثبت رجحان برقرار، 100 انڈیکس میں 600 پوائنٹس کا اضافہ\n",
      "کنٹینرز، ٹرک پکڑے جانے سے روزانہ کروڑوں کا نقصان ہو رہا ہے، پاکستان ٹرانسپورٹ کونسل\n",
      "حکومت کا پی ایس ڈی پی منصوبوں کو 3 سال میں مرحلہ وار مکمل کرنے کا فیصلہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247126/\n",
      "348 ارب ڈالر کے اثاثے : ایلون مسک دنیا کی تاریخ کے امیر ترین انسان بن گئے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247087/\n",
      "غیرٹیکسٹائل مصنوعات کی برآمدات میں 4 ماہ کے دوران 18 فیصد تک اضافہ\n",
      "سونے کی قیمتوں میں مسلسل چھٹے روز اضافہ، مزید 2200 روپے مہنگا ہوگیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247051/\n",
      "اسلامی بینکاری کیلئے نظرثانی شدہ شریعہ گورننس فریم ورک جاری\n",
      "آئی ایم ایف کی سخت شرائط، پبلک سیکٹر ڈیولپمنٹ پروگرام رکنے کے قریب پہنچ گیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247012/\n",
      "وفاق نے کراچی پورٹ تک خصوصی سڑک اور ریل کے قیام کی منظوری دے دی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247006/\n",
      "سونے کی قیمتوں میں آج بھی 2 ہزار 500 روپے کا بڑا اضافہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246976/\n",
      "اسٹاک مارکیٹ میں زبردست تیزی، 100 انڈیکس 99 ہزار کی بلند ترین سطح پر پہنچ گیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246938/\n",
      "بینکوں کا مقررہ حد سے زائد کیش ڈپازٹس پر ماہانہ 5 فیصد فیس عائد کرنے کا اعلان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246941/\n",
      "کراچی: صدیوں کی کتھا! (تئیسویں قسط)\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246860/\n",
      "اداریہ: ’ہماری آزادی فلسطینیوں کی آزادی کے بغیر نامکمل ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247435/\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247355/\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Skipping article 'Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News' due to missing content.\n",
      "چین میں پھنسی ایک اور پاکستانی لڑکی کی ویڈیو وائرل\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1105229/\n",
      "\"استحکام پاکستان پارٹی کیا پی ٹی آئی پارٹ 2 ہے\"\n",
      "\t--> Skipping article '\"استحکام پاکستان پارٹی کیا پی ٹی آئی پارٹ 2 ہے\"' due to missing content.\n",
      "\"بچے کو قریبی پولٹری فارم مالکان نے قتل کیا\"\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1038578/child-murder-in-larkana\n",
      "\"قاضی فائز عیسیٰ کے فیصلے نے پنڈورا باکس کھول دیا\"\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1221062/vlog-inside-the-courtroom-key-facts-from-qazi-faez-isas-lifetime-disqualification-case-verdict\n",
      "\t--> Successfully scraped 35 articles from 'business'.\n",
      "Scraping category 'sport'...\n",
      "\t--> Found 63 articles in 'sport'.\n",
      "چیمپئنز ٹرافی: پاکستان نے آئی سی سی، بھارت کا مجوزہ ہائبرڈ ماڈل یکسر مسترد کردیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247400/\n",
      "تیسرا ون ڈے: پاکستان نے زمبابوے کو 99 رنز سے شکست دیکر سیریز 1-2 سے اپنے نام کرلی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247364/\n",
      "پاکستان نے ٹی 20 بلائنڈ کرکٹ ورلڈ کپ کے سیمی فائنل کیلئے کوالیفائی کرلیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247349/\n",
      "زمبابوے کیخلاف سیریز: احمد دانیال، شاہنواز دھانی کو انجری، عباس آفریدی اور جہانداد خان منتخب\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247341/\n",
      "پاکستان اور زمبابوے کے درمیان کرکٹ میچوں میں بنے ریکاڈز پر ایک نظر\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246848/\n",
      "تنازعات میں اُلجھی پاکستانی ٹیم کا مشکل ترین دورہ آسٹریلیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1245310/\n",
      "کیا واقعی یوئیفا چیمپیئنز لیگ کا نیا فارمیٹ کلب فٹبال کی دنیا کا تاریخی لمحہ ہے؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1244518/\n",
      "بنگلہ دیش سے شرمناک شکست: پاکستان کرکٹ کو آخر یہ کیا ہوگیا؟\n",
      "چیمپئنز ٹرافی: ہائبرڈ ماڈل کے تحت 10 میچز اور ایک سیمی فائنل پاکستان میں کرانے کا پلان\n",
      "پی ٹی آئی احتجاج: ’سری لنکا اے‘ ٹیم کا وطن واپسی کا فیصلہ، بقیہ میچز ملتوی\n",
      "چیمپئنز ٹرافی: پاکستان نے آئی سی سی، بھارت کا مجوزہ ہائبرڈ ماڈل یکسر مسترد کردیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247400/\n",
      "تیسرا ون ڈے: پاکستان نے زمبابوے کو 99 رنز سے شکست دیکر سیریز 1-2 سے اپنے نام کرلی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247364/\n",
      "پاکستان نے ٹی 20 بلائنڈ کرکٹ ورلڈ کپ کے سیمی فائنل کیلئے کوالیفائی کرلیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247349/\n",
      "زمبابوے کیخلاف سیریز: احمد دانیال، شاہنواز دھانی کو انجری، عباس آفریدی اور جہانداد خان منتخب\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247341/\n",
      "چیمپئنز ٹرافی: آئی سی سی بورڈ کا اجلاس 29 نومبر کو پاک بھارت تنازع کا فیصلہ کرے گا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247239/\n",
      "دوسرا ون ڈے: صائم ایوب کی شاندار سنچری، پاکستان نے زمبابوے کو 10 وکٹوں سے شکست دے دی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247209/\n",
      "اداریہ: ’ہماری آزادی فلسطینیوں کی آزادی کے بغیر نامکمل ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247435/\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "کوپ 29: ترقی پذیر ممالک کو 300 ارب ڈالرز دینے سے کیا واقعی کوئی تبدیلی آسکے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247292/\n",
      "زمبابوے کیخلاف دوسرے ون ڈے کیلئے پاکستان ٹیم کا اعلان، طیب طاہر اور ابرار احمد ڈیبیو کریں گے\n",
      "پرتھ ٹیسٹ: بھارت نے آسٹریلیا کو 295 رنز سے شکست دے کر 47 سالہ ریکارڈ توڑ دیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247141/\n",
      "ٹی20 کی تاریخ کا کم ترین اسکور، پوری ٹیم صرف 7 رنز پر آؤٹ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247138/\n",
      "رشبھ پنت 27 کروڑ بھارتی روپے میں فروخت، آئی پی ایل کی تاریخ کے مہنگے ترین کھلاڑی بن گئے\n",
      "میکس ورسٹیپن نے لگاتار چوتھی مرتبہ فارمولا ون کا ٹائٹل اپنے نام کرلیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247102/\n",
      "پہلا ون ڈے: زمبابوے نے پاکستان کو ڈی ایل ایس میتھڈ کے تحت 80 رنز سے شکست دے دی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247073/\n",
      "پرتھ ٹیسٹ میں ویرات کوہلی کی سنچری کیساتھ فارم میں واپسی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247090/\n",
      "پاکستان بمقابلہ زمبابوے: دونوں ٹیمیں اورنج کیپ پہن کر کیوں کھیل رہی ہیں؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247081/\n",
      "'پاکستان میں جمہوریت کے نام پر آمریت قائم ہے'\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1176585/\n",
      "12 مئی 2007: جب پرویز مشرف نے مکا لہرایا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1103140/\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1234779/\n",
      "حکومت اور پی ٹی آئی میں مذاکرات، افتخار شیرازی کا تجزیہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247186/\n",
      "خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246336/\n",
      "چیمپئنز ٹرافی: پاک-بھارت تنازع پر آئی سی سی نے ہنگامی اجلاس طلب کر لیا، بھارتی میڈیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246987/\n",
      "محمد عباس نے سابق کپتان عمران خان کا ریکارڈ برابر کردیا\n",
      "پرتھ ٹیسٹ کے پہلے دن 17 وکٹیں گر گئیں، آسٹریلیا مشکلات سے دوچار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246963/\n",
      "پی سی بی نے چیمپئنز ٹرافی 2025 کیلئے سمیر احمد کو ڈائریکٹر تعینات کردیا\n",
      "پاکستان اور زمبابوے کے درمیان کرکٹ میچوں میں بنے ریکاڈز پر ایک نظر\n",
      "لاہور: سابق ٹیسٹ کرکٹر نذیر جونیئر انتقال کرگئے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246869/\n",
      "مایہ ناز ٹینس اسٹار رافیل نڈال کی شکست کے ساتھ کریئر کا اختتام\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246838/\n",
      "چیمپئنز ٹرافی: پاک بھارت تنازع پر آئی سی سی پریشان، ہنگامی بورڈ اجلاس بلائے جانے کا امکان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246812/\n",
      "فخر زمان میچ ونر ہے، فٹ ہوگا تو ترجیح دی جائے گی، عاقب جاوید\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246793/\n",
      "چیمپینز ٹرافی کا شیڈول جاری کرنے میں ایک روز باقی، آئی سی سی تاحال اعلان نہ کرسکا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246781/\n",
      "بھارت، پاکستان میں طے شدہ بلائنڈ ٹی20 کرکٹ ورلڈ کپ سے دستبردار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246731/\n",
      "کراچی: نجی ہوٹل میں آتشزدگی، قومی ویمن ون ڈے کپ ملتوی کر دیا گیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246661/\n",
      "عاقب جاوید چیمپئنز ٹرافی تک قومی وائٹ بال ٹیم کے ہیڈ کوچ مقرر\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246634/\n",
      "بھارت ہم سے بات کرے، پاکستان آنے کے حوالے سے خدشہ دور کردیں گے، محسن نقوی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246632/\n",
      "آسٹریلیا نے تیسرے ٹی20 میں پاکستان کو شکست دیکر سیریز میں وائٹ واش کردیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246617/\n",
      "پاکستان نے آسٹریلیا کےخلاف تیسرے ٹی20 کیلئے پلیئنگ الیون کا اعلان کردیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246607/\n",
      "چیمپئنز ٹرافی: بھارتی ہٹ دھرمی سے براڈ کاسٹرز کو نقصان کا اندیشہ، طے شدہ رقم میں کمی کا الٹی میٹم\n",
      "پی سی بی کی عاقب جاوید کو پاکستان وائٹ بال ٹیم کا ہیڈ کوچ بننے کی پیشکش\n",
      "سابق چیف سلیکٹر وہاب ریاض کی ایک بار پھر پی سی بی میں واپسی کا امکان\n",
      "اداریہ: ’ہماری آزادی فلسطینیوں کی آزادی کے بغیر نامکمل ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247435/\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247355/\n",
      "کوپ 29: ترقی پذیر ممالک کو 300 ارب ڈالرز دینے سے کیا واقعی کوئی تبدیلی آسکے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247292/\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "'پاکستان میں جمہوریت کے نام پر آمریت قائم ہے'\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1176585/\n",
      "12 مئی 2007: جب پرویز مشرف نے مکا لہرایا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1103140/\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1234779/\n",
      "حکومت اور پی ٹی آئی میں مذاکرات، افتخار شیرازی کا تجزیہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247186/\n",
      "خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246336/\n",
      "\t--> Successfully scraped 12 articles from 'sport'.\n",
      "Scraping category 'tech'...\n",
      "\t--> Found 59 articles in 'tech'.\n",
      "ملک کے مختلف شہروں میں پانچ دن سے انٹرنیٹ رفتار انتہائی سست\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247408/\n",
      "انٹرنیٹ پر کڑی پابندیاں، پاکستان تابناک مستقبل سے پیچھے رہ جائے گا، ماہرین\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247365/\n",
      "اسٹیک ہولڈرز کا وی پی این رجسٹریشن کی تاریخ میں توسیع کا مطالبہ\n",
      "بھارت کی سائبر سیکیورٹی کمپنی میڈیا کو خاموش کرا رہی ہے، رپورٹرز ود آؤٹ بارڈر\n",
      "ملک بھر میں انٹرنیٹ کی رفتار بہتر ہونا شروع\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247329/\n",
      "ملک میں انٹرنیٹ کی رفتار سست، شوبز شخصیات کو بھی مشکلات کا سامنا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247241/\n",
      "ریڈمی کا رواں برس کا سستا ترین فون پیش\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246811/\n",
      "نوکیا نے بٹن فون کو فور جی میں پیش کردیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1245240/\n",
      "”آنر“ کا ایکس سیریز کا معیاری فون پیش\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1244475/\n",
      "سام سنگ کا اے 16 پیش، 6 سال تک اپڈیٹ دینے کا اعلان\n",
      "کراچی سمیت ملک کے مختلف شہروں میں انٹرنیٹ سست روی کا شکار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247169/\n",
      "ملک بھر میں واٹس ایپ سروسز متاثر ہونے کی اطلاعات\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247085/\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247355/\n",
      "کوپ 29: ترقی پذیر ممالک کو 300 ارب ڈالرز دینے سے کیا واقعی کوئی تبدیلی آسکے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247292/\n",
      "مخالفین کے خوف میں مبتلا ریاست رکاوٹیں کھڑی کرکے کب تک جگ ہنسائی کا سبب بنتی رہے گی؟\n",
      "واٹس ایپ میں وائس نوٹ کو تحریر میں شامل کرنے کا فیچر پیش\n",
      "وفاقی حکومت کا تیز انٹرنیٹ کیلئے قومی فائبرآئزیشن پالیسی پر کام کا آغاز\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246995/\n",
      "بلیو اسکائی صارفین کی تعداد 2 کروڑ تک جا پہنچی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246982/\n",
      "امریکی حکومت گوگل کی سرچ انجن ’کروم‘ پر اجارہ داری ختم کرنے کی خواہاں\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246887/\n",
      "ریڈمی کا رواں برس کا سستا ترین فون پیش\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246811/\n",
      "پاکستان میں ’بلیو اسکائی‘ کی سروسز میں بھی خلل کی شکایات\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246730/\n",
      "’وی پی اینز پابندی: ’حکومت اپنے اقدامات سے ملک کو خانہ جنگی کی جانب دھکیل رہی ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246772/\n",
      "ٹوئٹر، ٹائی ٹینک اور ٹرمپ\n",
      "'پاکستان میں جمہوریت کے نام پر آمریت قائم ہے'\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1176585/\n",
      "12 مئی 2007: جب پرویز مشرف نے مکا لہرایا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1103140/\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1234779/\n",
      "PTI Final Protest: Talks Between Government And PTI | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247186/\n",
      "خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246336/\n",
      "غیر رجسٹرڈ وی پی اینز پر پابندی، انٹرنیٹ سروس فراہم کنندگان کا تحفظات کا اظہار\n",
      "ٹوئٹر سے مماثل پلیٹ فارم ’بلیو اسکائی‘ کی مقبولیت میں اچانک اضافہ\n",
      "ملکی سالمیت کیخلاف یا کردار کشی کیلئے وی پی این کا استعمال غیرشرعی ہے، علامہ راغب نعیمی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246653/\n",
      "وی پی این کے بغیر آئی ٹی انڈسٹری نہیں چل سکتی، چیئرمین پی ٹی اے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246648/\n",
      "کراچی میں سپارکو کی جدید ترین ریزولو آر اینڈ ڈی لیب کا افتتاح\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246636/\n",
      "رجسٹرڈ وی پی این پر بھی غیر شرعی مواد دیکھنا صریحاً ناجائز ہے، سربراہ اسلامی نظریاتی کونسل\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246584/\n",
      "وی پی این کا استعمال ’غیراسلامی قرار‘ دینے پر اسلامی نظریاتی کونسل کو تنقید کا سامنا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246555/\n",
      "واٹس ایپ پر اسٹیٹس اپڈیٹ نوٹیفکیشن بھیجنے کی آزمائش\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246522/\n",
      "وزارت داخلہ کا پی ٹی اے کو غیرقانونی ’وی پی اینز‘ کی بندش کیلئے خط، اسلامی نظریاتی کونسل کی حمایت\n",
      "فیس بک مارکیٹ پلیس کا غلط استعمال، یورپی یونین نے میٹا پر 84 کروڑ ڈالر کا جرمانہ لگادیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246424/\n",
      "آرٹیفیشل انٹیلی جنس چیٹ بورڈز سیکیورٹی رسک قرار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246377/\n",
      "ٹیکسوں کی ادائیگیوں کا نیا سسٹم ’ای پیمنٹ 2.0‘ متعارف\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246368/\n",
      "سپارکو کا چاند پر تحقیق کیلئے چینی مشن کا حصہ بننے کا اعلان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246354/\n",
      "پی ٹی اے نے وی پی این صارفین کیلئے نیا رجسٹریشن پورٹل متعارف کرادیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246340/\n",
      "’ملک بھر سے ہر روز فحش ویب سائٹس تک رسائی کی تقریباً 2 کروڑ کوششیں کی جاتی ہیں‘\n",
      "حکومت کا ’سیکیورٹی خدشات‘ کے پیش نظر وی پی اینز کیلئے سخت ضوابط متعارف کروانے کا فیصلہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246209/\n",
      "واٹس ایپ میں تصویر فیکٹ چیک کے فیچر کی آزمائش\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246177/\n",
      "ملک بھر میں وی پی این سروسز میں خلل کی وجہ سامنے آگئی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246135/\n",
      "بٹ کوائن پہلی بار 80 ہزار ڈالر کی سطح پر پہنچ گیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246136/\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "کوپ 29: ترقی پذیر ممالک کو 300 ارب ڈالرز دینے سے کیا واقعی کوئی تبدیلی آسکے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247292/\n",
      "مخالفین کے خوف میں مبتلا ریاست رکاوٹیں کھڑی کرکے کب تک جگ ہنسائی کا سبب بنتی رہے گی؟\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "'پاکستان میں جمہوریت کے نام پر آمریت قائم ہے'\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1176585/\n",
      "12 مئی 2007: جب پرویز مشرف نے مکا لہرایا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1103140/\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1234779/\n",
      "PTI Final Protest: Talks Between Government And PTI | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247186/\n",
      "خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246336/\n",
      "\t--> Successfully scraped 12 articles from 'tech'.\n",
      "Scraping category 'world'...\n",
      "\t--> Found 83 articles in 'world'.\n",
      "بھارت: سفاک قصائی نے ساتھ رہنے والی خاتون کو قتل کر کے 50 ٹکڑے کر ڈالے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247418/\n",
      "برطانیہ میں 2023 میں 9 لاکھ سے زیادہ مہاجرین کی آمد کا ریکارڈ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247413/\n",
      "بھارت کی سائبر سیکیورٹی کمپنی میڈیا کو خاموش کرا رہی ہے، رپورٹرز ود آؤٹ بارڈر\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247357/\n",
      "62 فیصد ’ڈیجیٹل کونٹینٹ کریٹرز‘ معلومات شیئر کرنے سے قبل فیکٹ چیک نہیں کرتے، یونیسکو\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247410/\n",
      "ابراہیم رئیسی کی وفات: ایران نے ساری قیاس آرائیاں دفن کردیں\n",
      "رفح پر حملہ: ’بنیامن نیتن یاہو امن کی چھوٹی سی کوشش پر بھی آمادہ نہیں‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1232693/\n",
      "کراچی کا سابق اسٹریٹ کرمنل، ایف بی آئی ایجنٹ کامران فریدی امریکی قید سے رہا\n",
      "ایرانی مصنوعات کی مقبولیت میں اضافہ، صارفین کیا کہتے ہیں؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1231675/\n",
      "امریکا میں نو منتخب صدر ڈونلڈ ٹرمپ کے ’ٹیرف نفاذ‘ سے ایشیا کو سستا خام تیل ملنے کا امکان\n",
      "سری لنکا میں سمندری طوفان، سیلاب سے 4 افراد ہلاک، ڈھائی لاکھ سے زیادہ بے گھر\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247385/\n",
      "سری لنکا میں سمندری طوفان، سیلاب سے 4 افراد ہلاک، ڈھائی لاکھ سے زیادہ بے گھر\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247385/\n",
      "بنگلہ دیش: ہندوؤں کے احتجاج کے دوران وکیل کی ہلاکت، 6 افراد گرفتار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247335/\n",
      "آئی سی سی پراسیکیوٹر نے میانمار جنتا چیف کے وارنٹ گرفتاری کی استدعا کردی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247327/\n",
      "گوتم اڈانی پر امریکا میں فرد جرم کے بعد ایک ہفتے میں ’اڈانی گروپ‘ کو 55 ارب ڈالر کا نقصان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247324/\n",
      "ڈونلڈ ٹرمپ کی نامزد کابینہ کے اراکین کو بم سے اڑانے کی دھمکیاں\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247350/\n",
      "کابل: پاکستانی ناظم الامور کی امارت اسلامیہ افغانستان کے وزیر دفاع سے ملاقات\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247346/\n",
      "بھارت: سفاک قصائی نے ساتھ رہنے والی خاتون کو قتل کر کے 50 ٹکڑے کر ڈالے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247418/\n",
      "بھارت کی سائبر سیکیورٹی کمپنی میڈیا کو خاموش کرا رہی ہے، رپورٹرز ود آؤٹ بارڈر\n",
      "بھارت: خاتون پائلٹ نے خودکشی کر لی، بوائے فرینڈ گرفتار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247344/\n",
      "بھارت: فوج کے اعلیٰ افسر نے خواتین فوجی افسروں کو انسانی ہمدردی سے عاری قرار دے دیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247257/\n",
      "بھارت: خاتون پائلٹ نے خودکشی کر لی، بوائے فرینڈ گرفتار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247344/\n",
      "حزب اللہ کا حسن نصراللہ کی شہادت کے 2 ماہ بعد نماز جنازہ کی تیاری کا اعلان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247333/\n",
      "افغان صوبہ بغلان میں مزار پر فائرنگ، 10 افراد جاں بحق\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1246967/\n",
      "امید ہے ٹرمپ کی جیت امریکا سے تعلقات میں نئے باب کا سبب بنے گی، افغان حکومت\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1245832/\n",
      "افغان طالبان کا میڈیا پر جانداروں کی تصاویر دکھانے پر پابندی کے قانون پر عملدرآمد کا اعلان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1244209/\n",
      "لیکچر دینے کے بجائے مقامی مسائل پر توجہ دیں، پاکستان کا افغان وزارت خارجہ کے بیان پر ردعمل\n",
      "بنگلہ دیش: ہندوؤں کے احتجاج کے دوران وکیل کی ہلاکت، 6 افراد گرفتار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247335/\n",
      "لارڈ ولیم ہیگ آکسفورڈ یونیورسٹی کے نئے چانسلر منتخب\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247332/\n",
      "اسپین کا غزہ میں اسرائیلی کارروائیوں کے خلاف نسل کشی کے مقدمے میں فریق بننے کا اعلان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1235170/\n",
      "پاکستان 8ویں بار اقوام متحدہ کی سلامتی کونسل کا رکن بننے کیلئے پرعزم\n",
      "اگلے 5سالوں میں زمین کا درجہ ڈیڑھ ڈگری سے تجاوز کر جانے کا امکان ہے، اقوام متحدہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1235123/\n",
      "یورپی ملک سلووینیا نے فلسطین کو باقاعدہ آزاد ریاست تسلیم کر لیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1235057/\n",
      "آئی سی سی پراسیکیوٹر نے میانمار جنتا چیف کے وارنٹ گرفتاری کی استدعا کردی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247327/\n",
      "جنوبی کوریا: سیئول میں نومبر کے دوران ریکارڈ برف باری، نظام زندگی مفلوج\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247314/\n",
      "حزب اللہ کا حسن نصراللہ کی شہادت کے 2 ماہ بعد نماز جنازہ کی تیاری کا اعلان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247333/\n",
      "اسرائیلی وزیراعظم نے لبنان میں سیزفائر معاہدے کی منظوری دے دی، امریکی میڈیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247176/\n",
      "یو اے ای: 3 روز سے لاپتا یہودی مذہبی پیشوا کی لاش برآمد، 3 ملزمان گرفتار\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247133/\n",
      "من مانی نہیں کرسکتے، عالمی عدالت کے ورانٹ گرفتاری پر عمل لازم ہے، سربراہ خارجہ پالیسی یورپی یونین\n",
      "گوتم اڈانی پر امریکا میں فرد جرم کے بعد ایک ہفتے میں ’اڈانی گروپ‘ کو 55 ارب ڈالر کا نقصان\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247324/\n",
      "لبنان میں اسرائیل اور حزب اللہ کے درمیان جنگ بندی, لوگوں کی گھروں کو واپسی شروع\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247301/\n",
      "نائجیریا میں تیل کے ٹینکر میں دھماکا، 94 افراد ہلاک، درجنوں زخمی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1244325/\n",
      "جنوبی افریقہ میں 90 خواتین سے ریپ کرنے والے شخص کو 42 بار عمر قید کی سزا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1243566/\n",
      "نائجیریا میں کشتی کو حادثہ، 150 افراد لاپتا\n",
      "مالی میں دہشتگردوں کا غیر معمولی حملہ، القاعدہ سے منسلک گروپ نے ذمہ داری قبول کرلی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1242432/\n",
      "امریکی قانون سازوں، بائیڈن، ٹرمپ انتظامیہ کے اہلکاروں اور ایمنسٹی کا عمران خان کی رہائی کا مطالبہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247285/\n",
      "بھارت: فوج کے اعلیٰ افسر نے خواتین فوجی افسروں کو انسانی ہمدردی سے عاری قرار دے دیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247257/\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "کوپ 29: ترقی پذیر ممالک کو 300 ارب ڈالرز دینے سے کیا واقعی کوئی تبدیلی آسکے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247292/\n",
      "مخالفین کے خوف میں مبتلا ریاست رکاوٹیں کھڑی کرکے کب تک جگ ہنسائی کا سبب بنتی رہے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247134/\n",
      "بھارت: مغلیہ دور کی مسجد کے سروے کے دوران جاں بحق افراد کی تعداد 6 ہوگئی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247235/\n",
      "نائیجیریا میں ’معجزاتی حمل‘ کے نام پر خواتین کے ساتھ دھوکے کا اسکینڈل\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247228/\n",
      "امریکا کا حکومت پاکستان پر انسانی حقوق، پی ٹی آئی کے حق احتجاج کے احترام پر زور\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247205/\n",
      "چیمپئنز ٹرافی: آئی سی سی بورڈ کا اجلاس 29 نومبر کو پاک بھارت تنازع کا فیصلہ کرے گا\n",
      "روس کی طالبان کو ’بلیک لسٹ‘ سے نکالنے کی یقین دہانی\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247202/\n",
      "رشتہ داروں کے ہاتھوں ہر 10 منٹ میں ایک عورت یا لڑکی کا قتل ہوتا ہے، رپورٹ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247199/\n",
      "’اڈانی گروپ کی کرپشن‘ پر بھارتی پارلیمنٹ میں گرما گرمی، کانگریس کا احتجاج\n",
      "اسرائیلی وزیراعظم نے لبنان میں سیزفائر معاہدے کی منظوری دے دی، امریکی میڈیا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247176/\n",
      "'پاکستان میں جمہوریت کے نام پر آمریت قائم ہے'\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1176585/\n",
      "12 مئی 2007: جب پرویز مشرف نے مکا لہرایا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1103140/\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1234779/\n",
      "PTI Final Protest: Talks Between Government And PTI | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247186/\n",
      "خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟\n",
      "\t--> Skipping article 'خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟' due to missing content.\n",
      "نیتن یاہو برطانیہ آئے تو عالمی عدالت کے فیصلے پر عمل کریں گے، وزیر خارجہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247174/\n",
      "فرانس: بیوی کو نشہ آور اشیا دے کر اجنبیوں سے ریپ کروانے والے ملزم کیلئے سخت سزا کا مطالبہ\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247170/\n",
      "بھارت: جنگلی حیات کی نگرانی کے ٹیکنالوجی آلات کا خواتین کو ڈرانے، ہراساں کرنے کیلئے استعمال\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247152/\n",
      "بیلا روس کے صدر الیگزینڈر لوکاشنکو 3 روزہ سرکاری دورے پر پاکستان پہنچ گئے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247156/\n",
      "یو اے ای: 3 روز سے لاپتا یہودی مذہبی پیشوا کی لاش برآمد، 3 ملزمان گرفتار\n",
      "سنگاپور میں کورونا کے بعد بھی سماجی تنہائی برقرار، لوگ چیٹ جی پی ٹی سے باتیں کرنے لگے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247137/\n",
      "’غیر قانونی مہاجرین کی بے دخلی‘ امریکی معیشت کیلئے خطرہ ثابت ہوسکتی ہے\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247131/\n",
      "بھارت: گوگل میپ سے رہنمائی لینے والی کار پل سے گرگئی، 3 افراد ہلاک\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247115/\n",
      "بھارت: اترپردیش میں مسجد کے سروے کے دوران تصادم، 2 افراد ہلاک\n",
      "’پاور از پاور۔۔۔‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247362/\n",
      "اداریہ: ’حکمران اتحاد نے مستقبل میں مظاہروں سے نمٹنے کا معیار طے کردیا ہے‘\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247355/\n",
      "کوپ 29: ترقی پذیر ممالک کو 300 ارب ڈالرز دینے سے کیا واقعی کوئی تبدیلی آسکے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247292/\n",
      "مخالفین کے خوف میں مبتلا ریاست رکاوٹیں کھڑی کرکے کب تک جگ ہنسائی کا سبب بنتی رہے گی؟\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247134/\n",
      "\t--> Skipping article due to missing title or link.\n",
      "\t--> Skipping article due to missing title or link.\n",
      "'پاکستان میں جمہوریت کے نام پر آمریت قائم ہے'\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1176585/\n",
      "12 مئی 2007: جب پرویز مشرف نے مکا لہرایا\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1103140/\n",
      "Gharida Farooqi Discloses Name, Who Is Behind Imran Khan’s Tweet | Khabar Se Khabar | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1234779/\n",
      "PTI Final Protest: Talks Between Government And PTI | Dawn News\n",
      "\t--> Failed to scrape article due to: 403 Client Error: Forbidden for url: https://www.dawnnews.tv/news/1247186/\n",
      "خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟\n",
      "\t--> Skipping article 'خیبرپختونخوا کے جنوبی اضلاع میں طالبان کی موجودگی ؟' due to missing content.\n",
      "\t--> Successfully scraped 13 articles from 'world'.\n"
     ]
    }
   ],
   "source": [
    "express_df = scraper.get_express_articles()\n",
    "dunya_df = scraper.get_dunya_articles()\n",
    "geo_df = scraper.get_geo_articles()\n",
    "jang_df = scraper.get_jang_articles()\n",
    "dawn_df = scraper.get_dawn_articles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn7TyroayZhg",
   "metadata": {
    "id": "nn7TyroayZhg"
   },
   "source": [
    "# Output\n",
    "- Save a combined csv of all 5 sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668040f6-1f3b-4400-8daa-39b1296a151e",
   "metadata": {
    "id": "668040f6-1f3b-4400-8daa-39b1296a151e"
   },
   "outputs": [],
   "source": [
    "old_df = pd.read_csv('data/data5.csv')\n",
    "combined_df = pd.concat([jang_df,geo_df,dunya_df,express_df,dawn_df], ignore_index=True)\n",
    "combined_df.to_csv('testdf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
