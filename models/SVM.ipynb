{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.9816933638443935\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "          Business       1.00      0.97      0.99        76\n",
      "     Entertainment       0.99      0.98      0.98        87\n",
      "     International       0.95      0.99      0.97        99\n",
      "Science-Technology       0.97      0.99      0.98        75\n",
      "            Sports       1.00      0.98      0.99       100\n",
      "\n",
      "          accuracy                           0.98       437\n",
      "         macro avg       0.98      0.98      0.98       437\n",
      "      weighted avg       0.98      0.98      0.98       437\n",
      "\n",
      "Accuracy: 0.9816933638443935\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "          Business       1.00      0.97      0.99        76\n",
      "     Entertainment       0.99      0.98      0.98        87\n",
      "     International       0.95      0.99      0.97        99\n",
      "Science-Technology       0.97      0.99      0.98        75\n",
      "            Sports       1.00      0.98      0.99       100\n",
      "\n",
      "          accuracy                           0.98       437\n",
      "         macro avg       0.98      0.98      0.98       437\n",
      "      weighted avg       0.98      0.98      0.98       437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# --- Load Dataset ---\n",
    "data = pd.read_csv('/Users/tahafaisal/Desktop/ml-news-classification/data/FINAL_DATASET.csv')\n",
    "\n",
    "# Load Urdu stopwords\n",
    "with open('/Users/tahafaisal/Desktop/ml-news-classification/data/stopwords.txt', 'r', encoding='utf-8') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "# --- Preprocessing Functions ---\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    return re.sub(r'[٠١٢٣٤٥٦٧٨٩]', '', text)  # Remove Urdu numerals\n",
    "\n",
    "def normalize_urdu(text):\n",
    "    text = re.sub(r'[؁؂؃؄؅؆؇؈؉؊؋،؛؟]', '', text)  # Remove Urdu punctuation\n",
    "    text = re.sub(r'[آإأٱ]', 'ا', text)  # Normalize different forms of 'alif'\n",
    "    text = re.sub(r'[ىېۍ]', 'ی', text)  # Normalize different forms of 'ye'\n",
    "    text = re.sub(r'[ۀہ]', 'ہ', text)  # Normalize 'heh'\n",
    "    text = re.sub(r'[ؤو]', 'و', text)  # Normalize 'waw'\n",
    "    text = re.sub(r'[ءئ]', 'ی', text)  # Normalize 'hamza' with 'ye'\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return re.findall(r'\\w+', text)  # Extract words using regex\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stopwords]\n",
    "\n",
    "def preprocess_urdu_text(text):\n",
    "    text = clean_text(text)  # Clean text\n",
    "    text = normalize_unicode(text)  # Normalize Unicode\n",
    "    text = normalize_urdu(text)  # Normalize Urdu-specific characters\n",
    "    tokens = tokenize_text(text)  # Tokenize text\n",
    "    tokens = remove_stopwords(tokens)  # Remove stopwords\n",
    "    return ' '.join(tokens)  # Return preprocessed text\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "data['title'] = data['title'].apply(preprocess_urdu_text)\n",
    "data['content'] = data['content'].apply(preprocess_urdu_text)\n",
    "data['combined'] = data['title'] + \" \" + data['content']\n",
    "\n",
    "# --- Feature Extraction ---\n",
    "# Use TF-IDF for feature representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=6000, ngram_range=(1, 2))  # Include unigrams and bigrams\n",
    "X = vectorizer.fit_transform(data['combined']).toarray()\n",
    "\n",
    "# Map string labels to numerical labels\n",
    "unique_labels = np.unique(data['gold_label'])\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "inverse_label_mapping = {idx: label for label, idx in label_mapping.items()}\n",
    "\n",
    "y = np.array([label_mapping[label] for label in data['gold_label']])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train XGBoost Classifier ---\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train a Support Vector Machine Classifier\n",
    "svm_model = SVC(kernel='linear', C=1, probability=True)  # You can tune 'C' and kernel type\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "y_pred_labels = [inverse_label_mapping[label] for label in y_pred]\n",
    "y_test_labels = [inverse_label_mapping[label] for label in y_test]\n",
    "\n",
    "# Evaluate the Model\n",
    "print(\"SVM Classifier Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_labels, y_pred_labels))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_labels, y_pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
